{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e8d7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from operator import add\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7eb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class RetinalDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.n_samples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_path[index]\n",
    "        mask_path = self.masks_path[index]\n",
    "\n",
    "        # Load image in BGR format\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Extract only the green channel\n",
    "        green = image[:, :, 1]  # Index 1 = green channel in BGR\n",
    "\n",
    "        # Normalize and convert to tensor\n",
    "        green = green / 255.0\n",
    "        green = np.expand_dims(green, axis=0).astype(np.float32)  # Shape: [1, H, W]\n",
    "        image = torch.from_numpy(green)\n",
    "\n",
    "        # Load and process the mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask / 255.0\n",
    "        mask = np.expand_dims(mask, axis=0).astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        # Get the filename\n",
    "        filename = os.path.basename(img_path)\n",
    "\n",
    "        return image, mask, filename\n",
    "    def __len__(self):\n",
    "            return self.n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acbded60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Focal_Tversky(nn.Module):\n",
    "    def __init__(self, alpha=0.3, beta=0.7, gamma=1.5, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta  = beta\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # logits, targets: (N, 1, H, W) or (N, H, W)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        N = targets.size(0)\n",
    "\n",
    "        # flatten per sample\n",
    "        probs  = probs.view(N, -1)\n",
    "        targets = targets.view(N, -1)\n",
    "\n",
    "        TP = (probs * targets).sum(dim=1)\n",
    "        FP = (probs * (1 - targets)).sum(dim=1)\n",
    "        FN = ((1 - probs) * targets).sum(dim=1)\n",
    "\n",
    "        smooth = torch.tensor(self.smooth, device=probs.device, dtype=probs.dtype)\n",
    "        tversky = (TP + smooth) / (TP + self.alpha * FP + self.beta * FN + smooth)\n",
    "\n",
    "        # focal modulation\n",
    "        loss = (1 - tversky) ** self.gamma\n",
    "\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6698c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = self.conv(x)\n",
    "        p = self.pool(s)\n",
    "        return s, p\n",
    "\n",
    "class attention_gate(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.Wg = nn.Sequential(\n",
    "            nn.Conv2d(in_c[0], out_c, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "        self.Ws = nn.Sequential(\n",
    "            nn.Conv2d(in_c[1], out_c, kernel_size=1, padding=0),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, g, s):\n",
    "        Wg = self.Wg(g)\n",
    "        Ws = self.Ws(s)\n",
    "        out = self.relu(Wg + Ws)\n",
    "        out = self.output(out)\n",
    "        return out * s\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.ag = attention_gate(in_c, out_c)\n",
    "        self.c1 = conv_block(in_c[0]+out_c, out_c)\n",
    "\n",
    "    def forward(self, x, s):\n",
    "        x = self.up(x)\n",
    "        s = self.ag(x, s)\n",
    "        x = torch.cat([x, s], axis=1)\n",
    "        x = self.c1(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.e1 = encoder_block(1, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        self.b1 = conv_block(512, 1024)\n",
    "\n",
    "        self.d1 = decoder_block([1024, 512], 512)\n",
    "        self.d2 = decoder_block([512, 256], 256)\n",
    "        self.d3 = decoder_block([256, 128], 128)\n",
    "        self.d4 = decoder_block([128, 64], 64)\n",
    "        \n",
    "        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s1, p1 = self.e1(x)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        b1 = self.b1(p4)\n",
    "\n",
    "        d1 = self.d1(b1, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "\n",
    "        output = self.output(d4)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50891b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Training and Evaluation \n",
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y, _ in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy() > 0.5\n",
    "    y_pred = torch.sigmoid(y_pred).cpu().numpy() > 0.5\n",
    "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
    "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
    "\n",
    "    return [\n",
    "        jaccard_score(y_true, y_pred, zero_division=0),\n",
    "        f1_score(y_true, y_pred, zero_division=0),\n",
    "        recall_score(y_true, y_pred, zero_division=0),\n",
    "        precision_score(y_true, y_pred, zero_division=0),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return np.concatenate([mask]*3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88bb673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeding(42)\n",
    "MODEL_NAME = \"Green_Attention_UNet_Focal_Tversky_Full\"\n",
    "MODEL_DIRECTORY = \"Green_Attention_Model_UNet_Focal_Tversky_Full\"\n",
    "create_directory(MODEL_DIRECTORY)\n",
    "RESULT_DIRECTORY = \"Green_Attention_Results_UNet_Focal_Tversky_Full\"\n",
    "create_directory(RESULT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752cce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/HS401/in00199/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load full training set \n",
    "train_images = sorted(glob(\"../final_dataset/train/images/*\"))\n",
    "train_masks  = sorted(glob(\"../final_dataset/train/masks/*\"))\n",
    "train_dataset = RetinalDataset(train_images, train_masks)\n",
    "\n",
    "# load test set and split it 50/50 into validation and test \n",
    "test_images = sorted(glob(\"../final_dataset/test/images/*\"))\n",
    "test_masks  = sorted(glob(\"../final_dataset/test/masks/*\"))\n",
    "full_test_dataset = RetinalDataset(test_images, test_masks)\n",
    "n_val = len(full_test_dataset) // 2\n",
    "n_test = len(full_test_dataset) - n_val\n",
    "valid_dataset, test_dataset = random_split(full_test_dataset, [n_val, n_test])\n",
    "\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model     = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "loss_fn   = Focal_Tversky()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "best_valid_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1812f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Time: 11m 47s\n",
      "\tTrain Loss: 0.7787 | Valid Loss: 0.6501\n",
      "\tAccuracy: 0.9883 | F1: 0.2538 | Dice: 0.3707 | Recall: 0.3760 | Precision: 0.3656 | Jaccard: 0.1564\n",
      "Best Green_Attention_UNet_Focal_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Time: 11m 17s\n",
      "\tTrain Loss: 0.5590 | Valid Loss: 0.6155\n",
      "\tAccuracy: 0.9912 | F1: 0.3070 | Dice: 0.3834 | Recall: 0.3151 | Precision: 0.4894 | Jaccard: 0.2022\n",
      "Best Green_Attention_UNet_Focal_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Time: 11m 17s\n",
      "\tTrain Loss: 0.5280 | Valid Loss: 0.6723\n",
      "\tAccuracy: 0.9917 | F1: 0.2772 | Dice: 0.3410 | Recall: 0.2392 | Precision: 0.5936 | Jaccard: 0.1859\n",
      "No improvement in validation loss for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Time: 11m 27s\n",
      "\tTrain Loss: 0.5056 | Valid Loss: 0.6321\n",
      "\tAccuracy: 0.9917 | F1: 0.3047 | Dice: 0.3777 | Recall: 0.2818 | Precision: 0.5724 | Jaccard: 0.2043\n",
      "No improvement in validation loss for 2 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Time: 11m 17s\n",
      "\tTrain Loss: 0.4848 | Valid Loss: 0.5877\n",
      "\tAccuracy: 0.9918 | F1: 0.3359 | Dice: 0.4073 | Recall: 0.3261 | Precision: 0.5423 | Jaccard: 0.2262\n",
      "Best Green_Attention_UNet_Focal_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Time: 11m 18s\n",
      "\tTrain Loss: 0.4736 | Valid Loss: 0.5761\n",
      "\tAccuracy: 0.9915 | F1: 0.3378 | Dice: 0.4071 | Recall: 0.3488 | Precision: 0.4888 | Jaccard: 0.2265\n",
      "Best Green_Attention_UNet_Focal_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Time: 11m 17s\n",
      "\tTrain Loss: 0.4682 | Valid Loss: 0.5979\n",
      "\tAccuracy: 0.9920 | F1: 0.3349 | Dice: 0.4025 | Recall: 0.3089 | Precision: 0.5772 | Jaccard: 0.2281\n",
      "No improvement in validation loss for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Time: 11m 16s\n",
      "\tTrain Loss: 0.4541 | Valid Loss: 0.5533\n",
      "\tAccuracy: 0.9909 | F1: 0.3475 | Dice: 0.4234 | Recall: 0.3971 | Precision: 0.4534 | Jaccard: 0.2343\n",
      "Best Green_Attention_UNet_Focal_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Time: 11m 18s\n",
      "\tTrain Loss: 0.4463 | Valid Loss: 0.5414\n",
      "\tAccuracy: 0.9920 | F1: 0.3754 | Dice: 0.4352 | Recall: 0.3639 | Precision: 0.5414 | Jaccard: 0.2587\n",
      "Best Green_Attention_UNet_Focal_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Time: 11m 18s\n",
      "\tTrain Loss: 0.4499 | Valid Loss: 0.7903\n",
      "\tAccuracy: 0.9913 | F1: 0.0947 | Dice: 0.1083 | Recall: 0.0616 | Precision: 0.4477 | Jaccard: 0.0584\n",
      "No improvement in validation loss for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Time: 11m 18s\n",
      "\tTrain Loss: 0.4269 | Valid Loss: 0.6657\n",
      "\tAccuracy: 0.9916 | F1: 0.2179 | Dice: 0.2613 | Recall: 0.1914 | Precision: 0.4114 | Jaccard: 0.1436\n",
      "No improvement in validation loss for 2 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Time: 11m 19s\n",
      "\tTrain Loss: 0.4791 | Valid Loss: 0.6652\n",
      "\tAccuracy: 0.9901 | F1: 0.2444 | Dice: 0.3084 | Recall: 0.2631 | Precision: 0.3726 | Jaccard: 0.1644\n",
      "No improvement in validation loss for 3 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Time: 11m 19s\n",
      "\tTrain Loss: 0.5673 | Valid Loss: 0.8540\n",
      "\tAccuracy: 0.9911 | F1: 0.0270 | Dice: 0.0320 | Recall: 0.0173 | Precision: 0.2117 | Jaccard: 0.0165\n",
      "No improvement in validation loss for 4 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Time: 11m 23s\n",
      "\tTrain Loss: 0.4086 | Valid Loss: 0.5940\n",
      "\tAccuracy: 0.9911 | F1: 0.3000 | Dice: 0.3567 | Recall: 0.2921 | Precision: 0.4578 | Jaccard: 0.2042\n",
      "No improvement in validation loss for 5 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Time: 11m 27s\n",
      "\tTrain Loss: 0.4999 | Valid Loss: 0.6774\n",
      "\tAccuracy: 0.9888 | F1: 0.1959 | Dice: 0.2708 | Recall: 0.2367 | Precision: 0.3164 | Jaccard: 0.1240\n",
      "No improvement in validation loss for 6 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Time: 11m 23s\n",
      "\tTrain Loss: 0.4088 | Valid Loss: 0.6441\n",
      "\tAccuracy: 0.9917 | F1: 0.2302 | Dice: 0.2876 | Recall: 0.2069 | Precision: 0.4719 | Jaccard: 0.1539\n",
      "No improvement in validation loss for 7 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Time: 11m 22s\n",
      "\tTrain Loss: 0.3711 | Valid Loss: 0.5725\n",
      "\tAccuracy: 0.9917 | F1: 0.2842 | Dice: 0.3498 | Recall: 0.2692 | Precision: 0.4992 | Jaccard: 0.1893\n",
      "No improvement in validation loss for 8 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Time: 11m 19s\n",
      "\tTrain Loss: 0.3600 | Valid Loss: 0.5505\n",
      "\tAccuracy: 0.9919 | F1: 0.3170 | Dice: 0.3752 | Recall: 0.3004 | Precision: 0.4996 | Jaccard: 0.2135\n",
      "No improvement in validation loss for 9 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Time: 11m 21s\n",
      "\tTrain Loss: 0.3392 | Valid Loss: 0.5520\n",
      "\tAccuracy: 0.9882 | F1: 0.3005 | Dice: 0.3671 | Recall: 0.3135 | Precision: 0.4428 | Jaccard: 0.2013\n",
      "No improvement in validation loss for 10 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Time: 11m 25s\n",
      "\tTrain Loss: 0.3277 | Valid Loss: 0.6085\n",
      "\tAccuracy: 0.9907 | F1: 0.2437 | Dice: 0.3064 | Recall: 0.2216 | Precision: 0.4964 | Jaccard: 0.1616\n",
      "No improvement in validation loss for 11 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Time: 11m 19s\n",
      "\tTrain Loss: 0.3218 | Valid Loss: 0.5705\n",
      "\tAccuracy: 0.9907 | F1: 0.2859 | Dice: 0.3412 | Recall: 0.2544 | Precision: 0.5182 | Jaccard: 0.1955\n",
      "No improvement in validation loss for 12 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Time: 11m 20s\n",
      "\tTrain Loss: 0.3144 | Valid Loss: 0.5575\n",
      "\tAccuracy: 0.9903 | F1: 0.2976 | Dice: 0.3610 | Recall: 0.2811 | Precision: 0.5045 | Jaccard: 0.2017\n",
      "No improvement in validation loss for 13 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Time: 11m 19s\n",
      "\tTrain Loss: 0.3127 | Valid Loss: 0.5668\n",
      "\tAccuracy: 0.9879 | F1: 0.2846 | Dice: 0.3548 | Recall: 0.2786 | Precision: 0.4882 | Jaccard: 0.1933\n",
      "No improvement in validation loss for 14 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Time: 11m 19s\n",
      "\tTrain Loss: 0.3118 | Valid Loss: 0.5621\n",
      "\tAccuracy: 0.9884 | F1: 0.2941 | Dice: 0.3684 | Recall: 0.2902 | Precision: 0.5044 | Jaccard: 0.1994\n",
      "No improvement in validation loss for 15 epoch(s)\n",
      "Early stopping triggered after 15 epochs with no improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "patience = 15\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(50):\n",
    "    start = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    model.eval()\n",
    "    valid_metrics = [0.0] * 5\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val, _ in tqdm(valid_loader, desc=\"Calculating Metrics\", leave=False):\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            y_pred = model(x_val)\n",
    "            valid_metrics = list(map(add, valid_metrics, calculate_metrics(y_val, y_pred)))\n",
    "\n",
    "    metrics_avg = [m / len(valid_loader) for m in valid_metrics]\n",
    "    jaccard, f1, recall, precision, accuracy = metrics_avg\n",
    "    dice = (2 * precision * recall) / (precision + recall + 1e-7)\n",
    "\n",
    "    mins, secs = epoch_time(start, time.time())\n",
    "    print(f\"Epoch {epoch+1:02} | Time: {mins}m {secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f}\")\n",
    "    print(f\"\\tAccuracy: {accuracy:.4f} | F1: {f1:.4f} | Dice: {dice:.4f} | Recall: {recall:.4f} | Precision: {precision:.4f} | Jaccard: {jaccard:.4f}\")\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        counter = 0  # reset counter\n",
    "        torch.save(model.state_dict(), f\"{MODEL_DIRECTORY}/{MODEL_NAME}.pth\")\n",
    "        print(f\"Best {MODEL_NAME} Saved\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"No improvement in validation loss for {counter} epoch(s)\")\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(f\"Early stopping triggered after {patience} epochs with no improvement.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66af66c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3100522/1207855148.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{MODEL_DIRECTORY}/{MODEL_NAME}.pth\", map_location=device))\n",
      "Testing: 100%|██████████| 113/113 [00:22<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.2050, F1: 0.3038, Recall: 0.3414, Precision: 0.4254, Accuracy: 0.9942\n",
      "FPS: 647.0579388624111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(f\"{MODEL_DIRECTORY}/{MODEL_NAME}.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on the held-out half of the test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "metrics_score = [0.0] * 5\n",
    "time_taken = []\n",
    "\n",
    "for x, y, fname in tqdm(test_loader, desc=\"Testing\", total=len(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        start = time.time()\n",
    "        pred_y = model(x)\n",
    "        time_taken.append(time.time() - start)\n",
    "        metrics_score = list(map(add, metrics_score, calculate_metrics(y, pred_y)))\n",
    "\n",
    "    # Use green-channel image directly (grayscale)\n",
    "    green_img = (x.cpu().numpy()[0, 0] * 255).astype(np.uint8)  # Shape: [H, W]\n",
    "\n",
    "    # Process ground truth and prediction\n",
    "    mask = (y.cpu().numpy()[0, 0] * 255).astype(np.uint8)\n",
    "    pred = (torch.sigmoid(pred_y).cpu().numpy()[0, 0] > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Convert masks to RGB overlays\n",
    "    mask_img = mask_parse(mask)\n",
    "    pred_img = mask_parse(pred)\n",
    "\n",
    "    # Resize masks to match green image if needed\n",
    "    h, w = green_img.shape\n",
    "    mask_img = cv2.resize(mask_img, (w, h))\n",
    "    pred_img = cv2.resize(pred_img, (w, h))\n",
    "\n",
    "    # Create vertical separator\n",
    "    line = np.ones((h, 10, 3), dtype=np.uint8) * 128\n",
    "\n",
    "    # Convert green image to 3-channel grayscale for compatibility\n",
    "    green_rgb = np.stack([green_img]*3, axis=-1)\n",
    "\n",
    "    # Concatenate images: green | line | mask | line | prediction\n",
    "    result_uint8 = np.concatenate([green_rgb, line, mask_img, line, pred_img], axis=1)\n",
    "\n",
    "    # Safe filename\n",
    "    if isinstance(fname, (list, tuple)):\n",
    "        fname = fname[0]\n",
    "    save_name = os.path.splitext(fname)[0] + \".png\"\n",
    "\n",
    "    # Save image\n",
    "    plt.imsave(f\"{RESULT_DIRECTORY}/{save_name}\", result_uint8)\n",
    "\n",
    "# Final metrics\n",
    "j, f1, r, p, a = [m / len(test_loader) for m in metrics_score]\n",
    "print(f\"Jaccard: {j:.4f}, F1: {f1:.4f}, Recall: {r:.4f}, Precision: {p:.4f}, Accuracy: {a:.4f}\")\n",
    "print(\"FPS:\", 1 / np.mean(time_taken))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
