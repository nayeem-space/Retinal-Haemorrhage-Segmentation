{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8d7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from operator import add\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions \n",
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7eb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \n",
    "class RetinalDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.n_samples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_path[index]\n",
    "        mask_path = self.masks_path[index]\n",
    "\n",
    "        # Load image in BGR format\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Extract only the green channel\n",
    "        green = image[:, :, 1]  # Index 1 = green channel in BGR\n",
    "\n",
    "        # Normalize and convert to tensor\n",
    "        green = green / 255.0\n",
    "        green = np.expand_dims(green, axis=0).astype(np.float32)  # Shape: [1, H, W]\n",
    "        image = torch.from_numpy(green)\n",
    "\n",
    "        # Load and process the mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask / 255.0\n",
    "        mask = np.expand_dims(mask, axis=0).astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        # Get the filename\n",
    "        filename = os.path.basename(img_path)\n",
    "\n",
    "        return image, mask, filename\n",
    "    def __len__(self):\n",
    "            return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbded60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.3, beta=0.7, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits).view(logits.size(0), -1)\n",
    "        targets = targets.view(targets.size(0), -1)\n",
    "\n",
    "        TP = (probs * targets).sum(dim=1)\n",
    "        FP = (probs * (1 - targets)).sum(dim=1)\n",
    "        FN = ((1 - probs) * targets).sum(dim=1)\n",
    "\n",
    "        tversky = (TP + self.smooth) / (TP + self.alpha * FP + self.beta * FN + self.smooth)\n",
    "        return (1 - tversky).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6698c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Additive attention block for U-Net skip connections.\"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        # W_g: gating signal transform\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # W_x: skip connection transform\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # psi: attention coefficient\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        # g: gating signal (from decoder), x: skip features (from encoder)\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi  # apply attention\n",
    "\n",
    "\n",
    "class TripleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 3 times.\"\"\"\n",
    "    def __init__(self, in_c, mid1_c, mid2_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid1_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid1_c)\n",
    "        self.conv2 = nn.Conv2d(mid1_c, mid2_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(mid2_c)\n",
    "        self.conv3 = nn.Conv2d(mid2_c, out_c, 3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 2 times.\"\"\"\n",
    "    def __init__(self, in_c, mid_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid_c)\n",
    "        self.conv2 = nn.Conv2d(mid_c, out_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net with attention gates on skip connections and additional subsampling concat.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.down1 = TripleConv(1, 32, 32, 64)\n",
    "        self.down2 = TripleConv(64, 64, 64, 128)\n",
    "        self.down3 = DoubleConv(128, 128, 256)\n",
    "        self.down4 = DoubleConv(256, 256, 256)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(256, 512, 256)\n",
    "\n",
    "        # Decoder up and conv\n",
    "        self.up4  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec4 = DoubleConv(256+256, 256, 256)\n",
    "        self.up3  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec3 = DoubleConv(256+256, 128, 128)\n",
    "        self.up2  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec2 = TripleConv(128+128, 64, 64, 64)\n",
    "        self.up1  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec1 = TripleConv(64+64, 32, 32, 32)\n",
    "\n",
    "        # Attention blocks for skip connections\n",
    "        self.att4 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att3 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att2 = AttentionBlock(F_g=128, F_l=128, F_int=64)\n",
    "        self.att1 = AttentionBlock(F_g=64,  F_l=64,  F_int=32)\n",
    "\n",
    "        # Final subsample, concat and output\n",
    "        self.final_pool       = nn.MaxPool2d(2, 2)\n",
    "        self.final_upsample   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.out_conv         = nn.Conv2d(33, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_image = x\n",
    "        # Encoder\n",
    "        x1  = self.down1(x)\n",
    "        x1p = self.pool(x1)\n",
    "        x2  = self.down2(x1p)\n",
    "        x2p = self.pool(x2)\n",
    "        x3  = self.down3(x2p)\n",
    "        x3p = self.pool(x3)\n",
    "        x4  = self.down4(x3p)\n",
    "        x4p = self.pool(x4)\n",
    "\n",
    "        # Bottleneck\n",
    "        xb  = self.bottleneck(x4p)\n",
    "\n",
    "        # Decoder + Attention\n",
    "        d4  = self.up4(xb)\n",
    "        x4a = self.att4(g=d4, x=x4)\n",
    "        d4  = torch.cat([x4a, d4], dim=1)\n",
    "        d4  = self.dec4(d4)\n",
    "\n",
    "        d3  = self.up3(d4)\n",
    "        x3a = self.att3(g=d3, x=x3)\n",
    "        d3  = torch.cat([x3a, d3], dim=1)\n",
    "        d3  = self.dec3(d3)\n",
    "\n",
    "        d2  = self.up2(d3)\n",
    "        x2a = self.att2(g=d2, x=x2)\n",
    "        d2  = torch.cat([x2a, d2], dim=1)\n",
    "        d2  = self.dec2(d2)\n",
    "\n",
    "        d1  = self.up1(d2)\n",
    "        x1a = self.att1(g=d1, x=x1)\n",
    "        d1  = torch.cat([x1a, d1], dim=1)\n",
    "        d1  = self.dec1(d1)\n",
    "\n",
    "        # Additional subsampling & concatenation\n",
    "        d1s = self.final_pool(d1)\n",
    "        ins = self.final_pool(input_image)\n",
    "        cat = torch.cat([d1s, ins], dim=1)\n",
    "        out = self.final_upsample(cat)\n",
    "        out = self.out_conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50891b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ============== Training and Evaluation ==============\n",
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y, _ in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy() > 0.5\n",
    "    y_pred = torch.sigmoid(y_pred).cpu().numpy() > 0.5\n",
    "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
    "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
    "\n",
    "    return [\n",
    "        jaccard_score(y_true, y_pred, zero_division=0),\n",
    "        f1_score(y_true, y_pred, zero_division=0),\n",
    "        recall_score(y_true, y_pred, zero_division=0),\n",
    "        precision_score(y_true, y_pred, zero_division=0),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return np.concatenate([mask]*3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88bb673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeding(42)\n",
    "MODEL_NAME = \"Green_Attention_Custom_Tversky_Full\"\n",
    "MODEL_DIRECTORY = \"Green_Model_Attention_Custom_Tversky_Full\"\n",
    "create_directory(MODEL_DIRECTORY)\n",
    "RESULT_DIRECTORY = \"Green_Results_Attention_Custom_Tversky_Full\"\n",
    "create_directory(RESULT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752cce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/HS401/in00199/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load full training set \n",
    "train_images = sorted(glob(\"../final_dataset/train/images/*\"))\n",
    "train_masks  = sorted(glob(\"../final_dataset/train/masks/*\"))\n",
    "train_dataset = RetinalDataset(train_images, train_masks)\n",
    "\n",
    "# load test set and split it 50/50 into validation and test \n",
    "test_images = sorted(glob(\"../final_dataset/test/images/*\"))\n",
    "test_masks  = sorted(glob(\"../final_dataset/test/masks/*\"))\n",
    "full_test_dataset = RetinalDataset(test_images, test_masks)\n",
    "n_val = len(full_test_dataset) // 2\n",
    "n_test = len(full_test_dataset) - n_val\n",
    "valid_dataset, test_dataset = random_split(full_test_dataset, [n_val, n_test])\n",
    "\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model     = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "loss_fn   = TverskyLoss()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "best_valid_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(40):\n",
    "    start = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    model.eval()\n",
    "    valid_metrics = [0.0] * 5\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val, _ in tqdm(valid_loader, desc=\"Calculating Metrics\", leave=False):\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            y_pred = model(x_val)\n",
    "            valid_metrics = list(map(add, valid_metrics, calculate_metrics(y_val, y_pred)))\n",
    "\n",
    "    metrics_avg = [m / len(valid_loader) for m in valid_metrics]\n",
    "    jaccard, f1, recall, precision, accuracy = metrics_avg\n",
    "    dice = (2 * precision * recall) / (precision + recall + 1e-7)\n",
    "\n",
    "    mins, secs = epoch_time(start, time.time())\n",
    "    print(f\"Epoch {epoch+1:02} | Time: {mins}m {secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f}\")\n",
    "    print(f\"\\tAccuracy: {accuracy:.4f} | F1: {f1:.4f} | Dice: {dice:.4f} | Recall: {recall:.4f} | Precision: {precision:.4f} | Jaccard: {jaccard:.4f}\")\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss  \n",
    "        torch.save(model.state_dict(), f\"{MODEL_DIRECTORY}/{MODEL_NAME}.pth\")\n",
    "        print(f\"Best {MODEL_NAME} Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66af66c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_928422/1207855148.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{MODEL_DIRECTORY}/{MODEL_NAME}.pth\", map_location=device))\n",
      "Testing: 100%|████████████████████████████████| 113/113 [00:21<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.2795, F1: 0.3976, Recall: 0.4510, Precision: 0.4542, Accuracy: 0.9944\n",
      "FPS: 144.3347949846044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(f\"{MODEL_DIRECTORY}/{MODEL_NAME}.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on the held-out half of the test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "metrics_score = [0.0] * 5\n",
    "time_taken = []\n",
    "\n",
    "for x, y, fname in tqdm(test_loader, desc=\"Testing\", total=len(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        start = time.time()\n",
    "        pred_y = model(x)\n",
    "        time_taken.append(time.time() - start)\n",
    "        metrics_score = list(map(add, metrics_score, calculate_metrics(y, pred_y)))\n",
    "\n",
    "    # Use green-channel image directly (grayscale)\n",
    "    green_img = (x.cpu().numpy()[0, 0] * 255).astype(np.uint8)  # Shape: [H, W]\n",
    "\n",
    "    # Process ground truth and prediction\n",
    "    mask = (y.cpu().numpy()[0, 0] * 255).astype(np.uint8)\n",
    "    pred = (torch.sigmoid(pred_y).cpu().numpy()[0, 0] > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Convert masks to RGB overlays\n",
    "    mask_img = mask_parse(mask)\n",
    "    pred_img = mask_parse(pred)\n",
    "\n",
    "    # Resize masks to match green image if needed\n",
    "    h, w = green_img.shape\n",
    "    mask_img = cv2.resize(mask_img, (w, h))\n",
    "    pred_img = cv2.resize(pred_img, (w, h))\n",
    "\n",
    "    # Create vertical separator\n",
    "    line = np.ones((h, 10, 3), dtype=np.uint8) * 128\n",
    "\n",
    "    # Convert green image to 3-channel grayscale for compatibility\n",
    "    green_rgb = np.stack([green_img]*3, axis=-1)\n",
    "\n",
    "    # Concatenate images: green | line | mask | line | prediction\n",
    "    result_uint8 = np.concatenate([green_rgb, line, mask_img, line, pred_img], axis=1)\n",
    "\n",
    "    # Safe filename\n",
    "    if isinstance(fname, (list, tuple)):\n",
    "        fname = fname[0]\n",
    "    save_name = os.path.splitext(fname)[0] + \".png\"\n",
    "\n",
    "    # Save image\n",
    "    plt.imsave(f\"{RESULT_DIRECTORY}/{save_name}\", result_uint8)\n",
    "\n",
    "# Final metrics\n",
    "j, f1, r, p, a = [m / len(test_loader) for m in metrics_score]\n",
    "print(f\"Jaccard: {j:.4f}, F1: {f1:.4f}, Recall: {r:.4f}, Precision: {p:.4f}, Accuracy: {a:.4f}\")\n",
    "print(\"FPS:\", 1 / np.mean(time_taken))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
