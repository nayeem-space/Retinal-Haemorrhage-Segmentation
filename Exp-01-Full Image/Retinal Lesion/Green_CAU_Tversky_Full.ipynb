{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71463670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to re-run this notebook before submitting. so decided to do reduce epoch to 30. first one was run with standard epoch set up as other experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8d7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from operator import add\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions \n",
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7eb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset \n",
    "class RetinalDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path = masks_path\n",
    "        self.n_samples = len(images_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.images_path[index]\n",
    "        mask_path = self.masks_path[index]\n",
    "\n",
    "        # Load image in BGR format\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Extract only the green channel\n",
    "        green = image[:, :, 1]  # Index 1 = green channel in BGR\n",
    "\n",
    "        # Normalize and convert to tensor\n",
    "        green = green / 255.0\n",
    "        green = np.expand_dims(green, axis=0).astype(np.float32)  # Shape: [1, H, W]\n",
    "        image = torch.from_numpy(green)\n",
    "\n",
    "        # Load and process the mask\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask / 255.0\n",
    "        mask = np.expand_dims(mask, axis=0).astype(np.float32)\n",
    "        mask = torch.from_numpy(mask)\n",
    "\n",
    "        # Get the filename\n",
    "        filename = os.path.basename(img_path)\n",
    "\n",
    "        return image, mask, filename\n",
    "    def __len__(self):\n",
    "            return self.n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acbded60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.3, beta=0.7, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        probs = torch.sigmoid(logits).view(logits.size(0), -1)\n",
    "        targets = targets.view(targets.size(0), -1)\n",
    "\n",
    "        TP = (probs * targets).sum(dim=1)\n",
    "        FP = (probs * (1 - targets)).sum(dim=1)\n",
    "        FN = ((1 - probs) * targets).sum(dim=1)\n",
    "\n",
    "        tversky = (TP + self.smooth) / (TP + self.alpha * FP + self.beta * FN + self.smooth)\n",
    "        return (1 - tversky).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6698c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Additive attention block for U-Net skip connections.\"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        # W_g: gating signal transform\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # W_x: skip connection transform\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # psi: attention coefficient\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        # g: gating signal (from decoder), x: skip features (from encoder)\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi  # apply attention\n",
    "\n",
    "\n",
    "class TripleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 3 times.\"\"\"\n",
    "    def __init__(self, in_c, mid1_c, mid2_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid1_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid1_c)\n",
    "        self.conv2 = nn.Conv2d(mid1_c, mid2_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(mid2_c)\n",
    "        self.conv3 = nn.Conv2d(mid2_c, out_c, 3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 2 times.\"\"\"\n",
    "    def __init__(self, in_c, mid_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid_c)\n",
    "        self.conv2 = nn.Conv2d(mid_c, out_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net with attention gates on skip connections and additional subsampling concat.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.down1 = TripleConv(1, 32, 32, 64)\n",
    "        self.down2 = TripleConv(64, 64, 64, 128)\n",
    "        self.down3 = DoubleConv(128, 128, 256)\n",
    "        self.down4 = DoubleConv(256, 256, 256)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(256, 512, 256)\n",
    "\n",
    "        # Decoder up and conv\n",
    "        self.up4  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec4 = DoubleConv(256+256, 256, 256)\n",
    "        self.up3  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec3 = DoubleConv(256+256, 128, 128)\n",
    "        self.up2  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec2 = TripleConv(128+128, 64, 64, 64)\n",
    "        self.up1  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec1 = TripleConv(64+64, 32, 32, 32)\n",
    "\n",
    "        # Attention blocks for skip connections\n",
    "        self.att4 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att3 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att2 = AttentionBlock(F_g=128, F_l=128, F_int=64)\n",
    "        self.att1 = AttentionBlock(F_g=64,  F_l=64,  F_int=32)\n",
    "\n",
    "        # Final subsample, concat and output\n",
    "        self.final_pool       = nn.MaxPool2d(2, 2)\n",
    "        self.final_upsample   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.out_conv         = nn.Conv2d(33, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_image = x\n",
    "        # Encoder\n",
    "        x1  = self.down1(x)\n",
    "        x1p = self.pool(x1)\n",
    "        x2  = self.down2(x1p)\n",
    "        x2p = self.pool(x2)\n",
    "        x3  = self.down3(x2p)\n",
    "        x3p = self.pool(x3)\n",
    "        x4  = self.down4(x3p)\n",
    "        x4p = self.pool(x4)\n",
    "\n",
    "        # Bottleneck\n",
    "        xb  = self.bottleneck(x4p)\n",
    "\n",
    "        # Decoder + Attention\n",
    "        d4  = self.up4(xb)\n",
    "        x4a = self.att4(g=d4, x=x4)\n",
    "        d4  = torch.cat([x4a, d4], dim=1)\n",
    "        d4  = self.dec4(d4)\n",
    "\n",
    "        d3  = self.up3(d4)\n",
    "        x3a = self.att3(g=d3, x=x3)\n",
    "        d3  = torch.cat([x3a, d3], dim=1)\n",
    "        d3  = self.dec3(d3)\n",
    "\n",
    "        d2  = self.up2(d3)\n",
    "        x2a = self.att2(g=d2, x=x2)\n",
    "        d2  = torch.cat([x2a, d2], dim=1)\n",
    "        d2  = self.dec2(d2)\n",
    "\n",
    "        d1  = self.up1(d2)\n",
    "        x1a = self.att1(g=d1, x=x1)\n",
    "        d1  = torch.cat([x1a, d1], dim=1)\n",
    "        d1  = self.dec1(d1)\n",
    "\n",
    "        # Additional subsampling & concatenation\n",
    "        d1s = self.final_pool(d1)\n",
    "        ins = self.final_pool(input_image)\n",
    "        cat = torch.cat([d1s, ins], dim=1)\n",
    "        out = self.final_upsample(cat)\n",
    "        out = self.out_conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50891b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation \n",
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x, y, _ in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, _ in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy() > 0.5\n",
    "    y_pred = torch.sigmoid(y_pred).cpu().numpy() > 0.5\n",
    "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
    "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
    "\n",
    "    return [\n",
    "        jaccard_score(y_true, y_pred, zero_division=0),\n",
    "        f1_score(y_true, y_pred, zero_division=0),\n",
    "        recall_score(y_true, y_pred, zero_division=0),\n",
    "        precision_score(y_true, y_pred, zero_division=0),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return np.concatenate([mask]*3, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88bb673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeding(42)\n",
    "MODEL_NAME = \"Green_Attention_Custom_Tversky_Full\"\n",
    "MODEL_DIRECTORY = \"Green_Model_Attention_Custom_Tversky_Full\"\n",
    "create_directory(MODEL_DIRECTORY)\n",
    "RESULT_DIRECTORY = \"Green_Results_Attention_Custom_Tversky_Full\"\n",
    "create_directory(RESULT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752cce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/HS401/in00199/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load full training set \n",
    "train_images = sorted(glob(\"./final_dataset/train/images/*\"))\n",
    "train_masks  = sorted(glob(\"./final_dataset/train/masks/*\"))\n",
    "train_dataset = RetinalDataset(train_images, train_masks)\n",
    "\n",
    "# load test set and split it 50/50 into validation and test\n",
    "test_images = sorted(glob(\"./final_dataset/test/images/*\"))\n",
    "test_masks  = sorted(glob(\"./final_dataset/test/masks/*\"))\n",
    "full_test_dataset = RetinalDataset(test_images, test_masks)\n",
    "n_val = len(full_test_dataset) // 2\n",
    "n_test = len(full_test_dataset) - n_val\n",
    "valid_dataset, test_dataset = random_split(full_test_dataset, [n_val, n_test])\n",
    "\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model     = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "loss_fn   = TverskyLoss()\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=0)\n",
    "\n",
    "best_valid_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1812f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Time: 13m 51s\n",
      "\tTrain Loss: 0.7126 | Valid Loss: 0.6923\n",
      "\tAccuracy: 0.9824 | F1: 0.3762 | Dice: 0.4311 | Recall: 0.4174 | Precision: 0.4457 | Jaccard: 0.2443\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Time: 11m 53s\n",
      "\tTrain Loss: 0.6228 | Valid Loss: 0.6379\n",
      "\tAccuracy: 0.9824 | F1: 0.4251 | Dice: 0.4745 | Recall: 0.5355 | Precision: 0.4259 | Jaccard: 0.2858\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Time: 11m 53s\n",
      "\tTrain Loss: 0.6006 | Valid Loss: 0.6614\n",
      "\tAccuracy: 0.9841 | F1: 0.4227 | Dice: 0.4714 | Recall: 0.4623 | Precision: 0.4808 | Jaccard: 0.2847\n",
      "No improvement for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Time: 11m 52s\n",
      "\tTrain Loss: 0.5907 | Valid Loss: 0.6517\n",
      "\tAccuracy: 0.9790 | F1: 0.4001 | Dice: 0.4527 | Recall: 0.5808 | Precision: 0.3709 | Jaccard: 0.2649\n",
      "No improvement for 2 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Time: 11m 51s\n",
      "\tTrain Loss: 0.5828 | Valid Loss: 0.6418\n",
      "\tAccuracy: 0.9822 | F1: 0.4268 | Dice: 0.4713 | Recall: 0.5214 | Precision: 0.4301 | Jaccard: 0.2895\n",
      "No improvement for 3 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Time: 11m 56s\n",
      "\tTrain Loss: 0.5775 | Valid Loss: 0.6370\n",
      "\tAccuracy: 0.9812 | F1: 0.4206 | Dice: 0.4706 | Recall: 0.5659 | Precision: 0.4028 | Jaccard: 0.2838\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Time: 11m 58s\n",
      "\tTrain Loss: 0.5715 | Valid Loss: 0.6499\n",
      "\tAccuracy: 0.9835 | F1: 0.4317 | Dice: 0.4764 | Recall: 0.4840 | Precision: 0.4691 | Jaccard: 0.2969\n",
      "No improvement for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Time: 11m 52s\n",
      "\tTrain Loss: 0.5617 | Valid Loss: 0.6343\n",
      "\tAccuracy: 0.9810 | F1: 0.4170 | Dice: 0.4651 | Recall: 0.5651 | Precision: 0.3952 | Jaccard: 0.2809\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Time: 12m 17s\n",
      "\tTrain Loss: 0.5585 | Valid Loss: 0.6289\n",
      "\tAccuracy: 0.9796 | F1: 0.4151 | Dice: 0.4679 | Recall: 0.6032 | Precision: 0.3822 | Jaccard: 0.2786\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Time: 11m 54s\n",
      "\tTrain Loss: 0.5576 | Valid Loss: 0.6192\n",
      "\tAccuracy: 0.9830 | F1: 0.4473 | Dice: 0.4928 | Recall: 0.5450 | Precision: 0.4497 | Jaccard: 0.3068\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Time: 11m 55s\n",
      "\tTrain Loss: 0.5518 | Valid Loss: 0.6304\n",
      "\tAccuracy: 0.9823 | F1: 0.4360 | Dice: 0.4899 | Recall: 0.5539 | Precision: 0.4392 | Jaccard: 0.2976\n",
      "No improvement for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Time: 11m 54s\n",
      "\tTrain Loss: 0.5476 | Valid Loss: 0.6177\n",
      "\tAccuracy: 0.9825 | F1: 0.4409 | Dice: 0.4909 | Recall: 0.5563 | Precision: 0.4393 | Jaccard: 0.3011\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Time: 11m 58s\n",
      "\tTrain Loss: 0.5396 | Valid Loss: 0.6193\n",
      "\tAccuracy: 0.9810 | F1: 0.4315 | Dice: 0.4840 | Recall: 0.5799 | Precision: 0.4153 | Jaccard: 0.2935\n",
      "No improvement for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Time: 11m 58s\n",
      "\tTrain Loss: 0.5330 | Valid Loss: 0.6221\n",
      "\tAccuracy: 0.9822 | F1: 0.4339 | Dice: 0.4819 | Recall: 0.5497 | Precision: 0.4291 | Jaccard: 0.2972\n",
      "No improvement for 2 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Time: 11m 55s\n",
      "\tTrain Loss: 0.5332 | Valid Loss: 0.6195\n",
      "\tAccuracy: 0.9815 | F1: 0.4361 | Dice: 0.4895 | Recall: 0.5806 | Precision: 0.4232 | Jaccard: 0.2971\n",
      "No improvement for 3 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Time: 11m 56s\n",
      "\tTrain Loss: 0.5238 | Valid Loss: 0.6484\n",
      "\tAccuracy: 0.9843 | F1: 0.4350 | Dice: 0.4782 | Recall: 0.4583 | Precision: 0.4998 | Jaccard: 0.2994\n",
      "No improvement for 4 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Time: 11m 55s\n",
      "\tTrain Loss: 0.5221 | Valid Loss: 0.6139\n",
      "\tAccuracy: 0.9824 | F1: 0.4430 | Dice: 0.4895 | Recall: 0.5627 | Precision: 0.4331 | Jaccard: 0.3021\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Time: 11m 53s\n",
      "\tTrain Loss: 0.5155 | Valid Loss: 0.6113\n",
      "\tAccuracy: 0.9799 | F1: 0.4278 | Dice: 0.4758 | Recall: 0.6141 | Precision: 0.3884 | Jaccard: 0.2891\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Time: 11m 58s\n",
      "\tTrain Loss: 0.5112 | Valid Loss: 0.6223\n",
      "\tAccuracy: 0.9832 | F1: 0.4490 | Dice: 0.4978 | Recall: 0.5338 | Precision: 0.4663 | Jaccard: 0.3079\n",
      "No improvement for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Time: 11m 56s\n",
      "\tTrain Loss: 0.5075 | Valid Loss: 0.6073\n",
      "\tAccuracy: 0.9829 | F1: 0.4501 | Dice: 0.4951 | Recall: 0.5558 | Precision: 0.4463 | Jaccard: 0.3091\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Time: 11m 54s\n",
      "\tTrain Loss: 0.5050 | Valid Loss: 0.6148\n",
      "\tAccuracy: 0.9823 | F1: 0.4498 | Dice: 0.4979 | Recall: 0.5730 | Precision: 0.4402 | Jaccard: 0.3065\n",
      "No improvement for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Time: 11m 55s\n",
      "\tTrain Loss: 0.5049 | Valid Loss: 0.6113\n",
      "\tAccuracy: 0.9825 | F1: 0.4530 | Dice: 0.4988 | Recall: 0.5664 | Precision: 0.4457 | Jaccard: 0.3094\n",
      "No improvement for 2 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Time: 11m 54s\n",
      "\tTrain Loss: 0.4954 | Valid Loss: 0.6125\n",
      "\tAccuracy: 0.9819 | F1: 0.4498 | Dice: 0.4963 | Recall: 0.5750 | Precision: 0.4365 | Jaccard: 0.3071\n",
      "No improvement for 3 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Time: 11m 57s\n",
      "\tTrain Loss: 0.4915 | Valid Loss: 0.5672\n",
      "\tAccuracy: 0.9802 | F1: 0.4371 | Dice: 0.4833 | Recall: 0.5901 | Precision: 0.4092 | Jaccard: 0.2974\n",
      "Best Green_Attention_Custom_Tversky_Full Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Time: 11m 57s\n",
      "\tTrain Loss: 0.6025 | Valid Loss: 0.6126\n",
      "\tAccuracy: 0.9818 | F1: 0.4089 | Dice: 0.4590 | Recall: 0.4948 | Precision: 0.4280 | Jaccard: 0.2731\n",
      "No improvement for 1 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Time: 11m 53s\n",
      "\tTrain Loss: 0.5707 | Valid Loss: 0.5950\n",
      "\tAccuracy: 0.9797 | F1: 0.4158 | Dice: 0.4662 | Recall: 0.5817 | Precision: 0.3890 | Jaccard: 0.2783\n",
      "No improvement for 2 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Time: 11m 53s\n",
      "\tTrain Loss: 0.6182 | Valid Loss: 0.5906\n",
      "\tAccuracy: 0.9814 | F1: 0.4191 | Dice: 0.4634 | Recall: 0.5271 | Precision: 0.4134 | Jaccard: 0.2837\n",
      "No improvement for 3 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Time: 11m 52s\n",
      "\tTrain Loss: 0.5700 | Valid Loss: 0.6327\n",
      "\tAccuracy: 0.9761 | F1: 0.3587 | Dice: 0.4010 | Recall: 0.5405 | Precision: 0.3188 | Jaccard: 0.2352\n",
      "No improvement for 4 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Time: 11m 54s\n",
      "\tTrain Loss: 0.5935 | Valid Loss: 0.6240\n",
      "\tAccuracy: 0.9802 | F1: 0.3688 | Dice: 0.4181 | Recall: 0.4668 | Precision: 0.3786 | Jaccard: 0.2444\n",
      "No improvement for 5 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Time: 11m 55s\n",
      "\tTrain Loss: 0.6525 | Valid Loss: 0.8061\n",
      "\tAccuracy: 0.9818 | F1: 0.0000 | Dice: 0.0000 | Recall: 0.0000 | Precision: 0.0000 | Jaccard: 0.0000\n",
      "No improvement for 6 epoch(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop_patience = 10\n",
    "\n",
    "for epoch in range(30):\n",
    "    start = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    model.eval()\n",
    "    valid_metrics = [0.0] * 5\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val, _ in tqdm(valid_loader, desc=\"Calculating Metrics\", leave=False):\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            y_pred = model(x_val)\n",
    "            valid_metrics = list(map(add, valid_metrics, calculate_metrics(y_val, y_pred)))\n",
    "\n",
    "    metrics_avg = [m / len(valid_loader) for m in valid_metrics]\n",
    "    jaccard, f1, recall, precision, accuracy = metrics_avg\n",
    "    dice = (2 * precision * recall) / (precision + recall + 1e-7)\n",
    "\n",
    "    mins, secs = epoch_time(start, time.time())\n",
    "    print(f\"Epoch {epoch+1:02} | Time: {mins}m {secs}s\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f}\")\n",
    "    print(f\"\\tAccuracy: {accuracy:.4f} | F1: {f1:.4f} | Dice: {dice:.4f} | Recall: {recall:.4f} | Precision: {precision:.4f} | Jaccard: {jaccard:.4f}\")\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), f\"{MODEL_DIRECTORY}/{MODEL_NAME}.pth\")\n",
    "        print(f\"Best {MODEL_NAME} Saved\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "\n",
    "    if epochs_no_improve >= early_stop_patience:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66af66c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_507860/1207855148.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{MODEL_DIRECTORY}/{MODEL_NAME}.pth\", map_location=device))\n",
      "Testing: 100%|██████████| 197/197 [00:34<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard: 0.2406, F1: 0.3486, Recall: 0.4847, Precision: 0.3293, Accuracy: 0.9831\n",
      "FPS: 243.24519141462505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(f\"{MODEL_DIRECTORY}/{MODEL_NAME}.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on the held-out half of the test set\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "metrics_score = [0.0] * 5\n",
    "time_taken = []\n",
    "\n",
    "for x, y, fname in tqdm(test_loader, desc=\"Testing\", total=len(test_loader)):\n",
    "    with torch.no_grad():\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        start = time.time()\n",
    "        pred_y = model(x)\n",
    "        time_taken.append(time.time() - start)\n",
    "        metrics_score = list(map(add, metrics_score, calculate_metrics(y, pred_y)))\n",
    "\n",
    "    # Use green-channel image directly (grayscale)\n",
    "    green_img = (x.cpu().numpy()[0, 0] * 255).astype(np.uint8)  # Shape: [H, W]\n",
    "\n",
    "    # Process ground truth and prediction\n",
    "    mask = (y.cpu().numpy()[0, 0] * 255).astype(np.uint8)\n",
    "    pred = (torch.sigmoid(pred_y).cpu().numpy()[0, 0] > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    # Convert masks to RGB overlays\n",
    "    mask_img = mask_parse(mask)\n",
    "    pred_img = mask_parse(pred)\n",
    "\n",
    "    # Resize masks to match green image if needed\n",
    "    h, w = green_img.shape\n",
    "    mask_img = cv2.resize(mask_img, (w, h))\n",
    "    pred_img = cv2.resize(pred_img, (w, h))\n",
    "\n",
    "    # Create vertical separator\n",
    "    line = np.ones((h, 10, 3), dtype=np.uint8) * 128\n",
    "\n",
    "    # Convert green image to 3-channel grayscale for compatibility\n",
    "    green_rgb = np.stack([green_img]*3, axis=-1)\n",
    "\n",
    "    # Concatenate images: green | line | mask | line | prediction\n",
    "    result_uint8 = np.concatenate([green_rgb, line, mask_img, line, pred_img], axis=1)\n",
    "\n",
    "    # Safe filename\n",
    "    if isinstance(fname, (list, tuple)):\n",
    "        fname = fname[0]\n",
    "    save_name = os.path.splitext(fname)[0] + \".png\"\n",
    "\n",
    "    # Save image\n",
    "    plt.imsave(f\"{RESULT_DIRECTORY}/{save_name}\", result_uint8)\n",
    "\n",
    "# Final metrics\n",
    "j, f1, r, p, a = [m / len(test_loader) for m in metrics_score]\n",
    "print(f\"Jaccard: {j:.4f}, F1: {f1:.4f}, Recall: {r:.4f}, Precision: {p:.4f}, Accuracy: {a:.4f}\")\n",
    "print(\"FPS:\", 1 / np.mean(time_taken))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
