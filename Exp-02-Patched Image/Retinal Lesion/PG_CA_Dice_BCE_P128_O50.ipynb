{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89b0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from operator import add\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch / Batch Variables \n",
    "PATCH_SIZE = 128    # 32, 64, 128\n",
    "OVERLAP    = 0.5   # 0.0, 0.25, 0.5, 0.8\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 40\n",
    "PATIENCE = 10\n",
    "\n",
    "MODEL_NAME       = f\"G_Custom_Attention_Dice_BCE_P{PATCH_SIZE}_O{int(OVERLAP*100)}\"\n",
    "MODEL_DIRECTORY  = f\"G_Model_Custom_Attention_Dice_BCE_P{PATCH_SIZE}_O{int(OVERLAP*100)}\"\n",
    "RESULT_DIRECTORY = f\"G_Results_Custom_Attention_Dice_BCE_P{PATCH_SIZE}_O{int(OVERLAP*100)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacd1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    mins = int(elapsed_time / 60)\n",
    "    secs = int(elapsed_time - mins*60)\n",
    "    return mins, secs\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy() > 0.5\n",
    "    y_pred = torch.sigmoid(y_pred).cpu().numpy() > 0.5\n",
    "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
    "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
    "    return [\n",
    "        jaccard_score(y_true, y_pred, zero_division=0),\n",
    "        f1_score(y_true, y_pred, zero_division=0),\n",
    "        recall_score(y_true, y_pred, zero_division=0),\n",
    "        precision_score(y_true, y_pred, zero_division=0),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return np.concatenate([mask]*3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10dd8a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchRetinalDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, patch_size, overlap):\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = int(patch_size * (1 - overlap))\n",
    "\n",
    "        self.patches = []  # list of (image_index, y, x)\n",
    "\n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "\n",
    "        for img_path, msk_path in zip(images_path, masks_path):\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)[:, :, 1] / 255.0  # green channel\n",
    "            msk = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "\n",
    "            H, W = img.shape\n",
    "            self.images.append(img)\n",
    "            self.masks.append(msk)\n",
    "\n",
    "            for y in range(0, H - patch_size + 1, self.stride):\n",
    "                for x in range(0, W - patch_size + 1, self.stride):\n",
    "                    self.patches.append((len(self.images) - 1, y, x))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_idx, y, x = self.patches[idx]\n",
    "        img = self.images[img_idx]\n",
    "        msk = self.masks[img_idx]\n",
    "\n",
    "        patch = img[y:y+self.patch_size, x:x+self.patch_size]\n",
    "        mask  = msk[y:y+self.patch_size, x:x+self.patch_size]\n",
    "\n",
    "        patch_tensor = torch.from_numpy(patch[None].astype(np.float32))\n",
    "        mask_tensor  = torch.from_numpy(mask[None].astype(np.float32))\n",
    "        return patch_tensor, mask_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bee75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.smooth = smooth\n",
    "        self.bce_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # BCE component (stable, with logits)\n",
    "        bce_loss = self.bce_fn(logits, targets)\n",
    "\n",
    "        # Dice component (per-sample)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        batch_size = probs.shape[0]\n",
    "        dice_losses = []\n",
    "        for i in range(batch_size):\n",
    "            p = probs[i].view(-1)\n",
    "            \n",
    "            g = targets[i].view(-1)\n",
    "            inter = (p * g).sum()\n",
    "            dice = 1 - (2*inter + self.smooth) / (p.sum() + g.sum() + self.smooth)\n",
    "            dice_losses.append(dice)\n",
    "        dice_loss = torch.stack(dice_losses).mean()\n",
    "\n",
    "        return self.alpha * dice_loss + (1 - self.alpha) * bce_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ddfb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Additive attention block for U-Net skip connections.\"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        # W_g: gating signal transform\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # W_x: skip connection transform\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # psi: attention coefficient\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        # g: gating signal (from decoder), x: skip features (from encoder)\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi  # apply attention\n",
    "\n",
    "\n",
    "class TripleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 3 times.\"\"\"\n",
    "    def __init__(self, in_c, mid1_c, mid2_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid1_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid1_c)\n",
    "        self.conv2 = nn.Conv2d(mid1_c, mid2_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(mid2_c)\n",
    "        self.conv3 = nn.Conv2d(mid2_c, out_c, 3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 2 times.\"\"\"\n",
    "    def __init__(self, in_c, mid_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid_c)\n",
    "        self.conv2 = nn.Conv2d(mid_c, out_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net with attention gates on skip connections and additional subsampling concat.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.down1 = TripleConv(1, 32, 32, 64)\n",
    "        self.down2 = TripleConv(64, 64, 64, 128)\n",
    "        self.down3 = DoubleConv(128, 128, 256)\n",
    "        self.down4 = DoubleConv(256, 256, 256)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(256, 512, 256)\n",
    "\n",
    "        # Decoder up and conv\n",
    "        self.up4  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec4 = DoubleConv(256+256, 256, 256)\n",
    "        self.up3  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec3 = DoubleConv(256+256, 128, 128)\n",
    "        self.up2  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec2 = TripleConv(128+128, 64, 64, 64)\n",
    "        self.up1  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec1 = TripleConv(64+64, 32, 32, 32)\n",
    "\n",
    "        # Attention blocks for skip connections\n",
    "        self.att4 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att3 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att2 = AttentionBlock(F_g=128, F_l=128, F_int=64)\n",
    "        self.att1 = AttentionBlock(F_g=64,  F_l=64,  F_int=32)\n",
    "\n",
    "        # Final subsample, concat and output\n",
    "        self.final_pool       = nn.MaxPool2d(2, 2)\n",
    "        self.final_upsample   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.out_conv         = nn.Conv2d(33, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_image = x\n",
    "        # Encoder\n",
    "        x1  = self.down1(x)\n",
    "        x1p = self.pool(x1)\n",
    "        x2  = self.down2(x1p)\n",
    "        x2p = self.pool(x2)\n",
    "        x3  = self.down3(x2p)\n",
    "        x3p = self.pool(x3)\n",
    "        x4  = self.down4(x3p)\n",
    "        x4p = self.pool(x4)\n",
    "\n",
    "        # Bottleneck\n",
    "        xb  = self.bottleneck(x4p)\n",
    "\n",
    "        # Decoder + Attention\n",
    "        d4  = self.up4(xb)\n",
    "        x4a = self.att4(g=d4, x=x4)\n",
    "        d4  = torch.cat([x4a, d4], dim=1)\n",
    "        d4  = self.dec4(d4)\n",
    "\n",
    "        d3  = self.up3(d4)\n",
    "        x3a = self.att3(g=d3, x=x3)\n",
    "        d3  = torch.cat([x3a, d3], dim=1)\n",
    "        d3  = self.dec3(d3)\n",
    "\n",
    "        d2  = self.up2(d3)\n",
    "        x2a = self.att2(g=d2, x=x2)\n",
    "        d2  = torch.cat([x2a, d2], dim=1)\n",
    "        d2  = self.dec2(d2)\n",
    "\n",
    "        d1  = self.up1(d2)\n",
    "        x1a = self.att1(g=d1, x=x1)\n",
    "        d1  = torch.cat([x1a, d1], dim=1)\n",
    "        d1  = self.dec1(d1)\n",
    "\n",
    "        # Additional subsampling & concatenation\n",
    "        d1s = self.final_pool(d1)\n",
    "        ins = self.final_pool(input_image)\n",
    "        cat = torch.cat([d1s, ins], dim=1)\n",
    "        out = self.final_upsample(cat)\n",
    "        out = self.out_conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c059fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeding(42)\n",
    "create_directory(MODEL_DIRECTORY)\n",
    "create_directory(RESULT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/HS401/in00199/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load file lists\n",
    "train_images = sorted(glob(\"./final_dataset/train/images/*\"))\n",
    "train_masks  = sorted(glob(\"./final_dataset/train/masks/*\"))\n",
    "test_images  = sorted(glob(\"./final_dataset/test/images/*\"))\n",
    "test_masks   = sorted(glob(\"./final_dataset/test/masks/*\"))\n",
    "\n",
    "# build datasets\n",
    "train_ds_full = PatchRetinalDataset(train_images, train_masks, PATCH_SIZE, OVERLAP)\n",
    "test_ds_full  = PatchRetinalDataset(test_images, test_masks, PATCH_SIZE, OVERLAP)\n",
    "\n",
    "# split test into val/test\n",
    "n_val = len(test_ds_full) // 2\n",
    "n_test = len(test_ds_full) - n_val\n",
    "valid_ds, test_ds = random_split(test_ds_full, [n_val, n_test])\n",
    "\n",
    "train_loader = DataLoader(train_ds_full, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2)\n",
    "valid_loader = DataLoader(valid_ds,      batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# setup\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model     = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "loss_fn   = DiceBCELoss()\n",
    "\n",
    "# training/eval functions\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    for x, y in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total += loss.item()\n",
    "    return total / len(loader)\n",
    "\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc=\"Valid\", leave=False):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            total += loss_fn(model(x), y).item()\n",
    "    return total / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9080927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/40 | 35m 32s\n",
      "Train: 0.4634 | Valid: 0.4577\n",
      "Acc:0.9803 F1:0.4718 Dice:0.4829 Rec:0.5051 Prec:0.4625 Jac:0.3135\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/40 | 35m 32s\n",
      "Train: 0.4386 | Valid: 0.4572\n",
      "Acc:0.9817 F1:0.4972 Dice:0.5078 Rec:0.5208 Prec:0.4955 Jac:0.3365\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/40 | 35m 32s\n",
      "Train: 0.4272 | Valid: 0.4629\n",
      "Acc:0.9789 F1:0.4734 Dice:0.4854 Rec:0.5354 Prec:0.4440 Jac:0.3159\n",
      "No improvement for 1/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/40 | 35m 32s\n",
      "Train: 0.4166 | Valid: 0.4697\n",
      "Acc:0.9840 F1:0.4557 Dice:0.4659 Rec:0.3760 Prec:0.6125 Jac:0.3004\n",
      "No improvement for 2/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/40 | 35m 31s\n",
      "Train: 0.4079 | Valid: 0.4694\n",
      "Acc:0.9811 F1:0.4890 Dice:0.5012 Rec:0.5131 Prec:0.4899 Jac:0.3294\n",
      "No improvement for 3/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/40 | 35m 34s\n",
      "Train: 0.4007 | Valid: 0.4683\n",
      "Acc:0.9826 F1:0.4886 Dice:0.4999 Rec:0.4739 Prec:0.5290 Jac:0.3283\n",
      "No improvement for 4/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07/40 | 35m 34s\n",
      "Train: 0.3946 | Valid: 0.4724\n",
      "Acc:0.9811 F1:0.4715 Dice:0.4829 Rec:0.4773 Prec:0.4887 Jac:0.3143\n",
      "No improvement for 5/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08/40 | 35m 34s\n",
      "Train: 0.3893 | Valid: 0.4720\n",
      "Acc:0.9826 F1:0.4681 Dice:0.4782 Rec:0.4347 Prec:0.5314 Jac:0.3105\n",
      "No improvement for 6/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09/40 | 35m 34s\n",
      "Train: 0.3781 | Valid: 0.4753\n",
      "Acc:0.9834 F1:0.4852 Dice:0.4961 Rec:0.4417 Prec:0.5657 Jac:0.3259\n",
      "No improvement for 7/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40 | 35m 35s\n",
      "Train: 0.3740 | Valid: 0.4782\n",
      "Acc:0.9836 F1:0.4817 Dice:0.4930 Rec:0.4306 Prec:0.5764 Jac:0.3230\n",
      "No improvement for 8/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40 | 35m 35s\n",
      "Train: 0.3716 | Valid: 0.4786\n",
      "Acc:0.9836 F1:0.4800 Dice:0.4910 Rec:0.4276 Prec:0.5764 Jac:0.3214\n",
      "No improvement for 9/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40 | 35m 34s\n",
      "Train: 0.3696 | Valid: 0.4813\n",
      "Acc:0.9837 F1:0.4762 Dice:0.4875 Rec:0.4189 Prec:0.5828 Jac:0.3183\n",
      "No improvement for 10/10 epochs\n",
      "Stopping early after 10 epochs without improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Training Loop \n",
    "early_stop_counter = 0\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "for epoch in range(EPOCH):\n",
    "    start = time.time()\n",
    "    tr_loss = train_epoch(model, train_loader)\n",
    "    va_loss = eval_epoch(model, valid_loader)\n",
    "    scheduler.step(va_loss)\n",
    "\n",
    "    # compute metrics on validation patches\n",
    "    model.eval()\n",
    "    mets = [0.0]*5\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm(valid_loader, desc=\"Val Metrics\", leave=False):\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            mets = list(map(add, mets, calculate_metrics(y, model(x))))\n",
    "    mets = [m/len(valid_loader) for m in mets]\n",
    "    j,f1,r,p,a = mets\n",
    "    dice = (2*p*r)/(p+r+1e-7)\n",
    "    mins, secs = epoch_time(start, time.time())\n",
    "    print(f\"Epoch {epoch+1:02}/{EPOCH} | {mins}m {secs}s\")\n",
    "    print(f\"Train: {tr_loss:.4f} | Valid: {va_loss:.4f}\")\n",
    "    print(f\"Acc:{a:.4f} F1:{f1:.4f} Dice:{dice:.4f} Rec:{r:.4f} Prec:{p:.4f} Jac:{j:.4f}\")\n",
    "\n",
    "    if va_loss < best_loss:\n",
    "        best_loss = va_loss\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIRECTORY, MODEL_NAME+\".pth\"))\n",
    "        print(\"Saved best model\")\n",
    "        early_stop_counter = 0\n",
    "   \n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"No improvement for {early_stop_counter}/{PATIENCE} epochs\")\n",
    "\n",
    "    if early_stop_counter >= PATIENCE:\n",
    "        print(f\"Stopping early after {PATIENCE} epochs without improvement.\")\n",
    "        break\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfd403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_276807/3131743033.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\n",
      "Testing: 100%|████████████████████████████████| 393/393 [01:34<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics:\n",
      "  Jaccard:   0.2443\n",
      "  F1 Score:  0.3568\n",
      "  Recall:    0.4251\n",
      "  Precision: 0.3899\n",
      "  Accuracy:  0.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing & Final Metrics \n",
    "model.load_state_dict(torch.load(\n",
    "    os.path.join(MODEL_DIRECTORY, MODEL_NAME + \".pth\"),\n",
    "    map_location=device\n",
    "))\n",
    "model.eval()\n",
    "\n",
    "metrics_score = [0.0] * 5\n",
    "\n",
    "# Loop over original full images\n",
    "for i in tqdm(range(len(test_images)), desc=\"Testing\"):\n",
    "    img_path = test_images[i]\n",
    "    msk_path = test_masks[i]\n",
    "\n",
    "    # Load full-size green channel and mask\n",
    "    green = cv2.imread(img_path, cv2.IMREAD_COLOR)[:, :, 1] / 255.0\n",
    "    mask = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "    H, W = green.shape\n",
    "\n",
    "    # Sliding window inference\n",
    "    pred_accum = np.zeros((H, W), dtype=np.float32)\n",
    "    count_accum = np.zeros((H, W), dtype=np.float32)\n",
    "    stride = int(PATCH_SIZE * (1 - OVERLAP))\n",
    "\n",
    "    for y in range(0, H - PATCH_SIZE + 1, stride):\n",
    "        for x in range(0, W - PATCH_SIZE + 1, stride):\n",
    "            patch = green[y:y+PATCH_SIZE, x:x+PATCH_SIZE]\n",
    "            patch_tensor = torch.from_numpy(patch[None, None].astype(np.float32)).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = torch.sigmoid(model(patch_tensor))[0, 0].cpu().numpy()\n",
    "\n",
    "            pred_accum[y:y+PATCH_SIZE, x:x+PATCH_SIZE] += pred\n",
    "            count_accum[y:y+PATCH_SIZE, x:x+PATCH_SIZE] += 1.0\n",
    "\n",
    "    pred_avg = pred_accum / np.maximum(count_accum, 1e-6)\n",
    "    pred_bin = (pred_avg > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Metrics\n",
    "    y_true = mask.reshape(-1) > 0.5\n",
    "    y_pred = pred_bin.reshape(-1) > 0.5\n",
    "    mets = [\n",
    "        jaccard_score(y_true, y_pred, zero_division=0),\n",
    "        f1_score(y_true, y_pred, zero_division=0),\n",
    "        recall_score(y_true, y_pred, zero_division=0),\n",
    "        precision_score(y_true, y_pred, zero_division=0),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "    metrics_score = list(map(add, metrics_score, mets))\n",
    "\n",
    "    # Save composite\n",
    "    green_rgb = np.stack([(green * 255).astype(np.uint8)] * 3, axis=-1)\n",
    "    mask_rgb = mask_parse((mask * 255).astype(np.uint8))\n",
    "    pred_rgb = mask_parse((pred_bin * 255).astype(np.uint8))\n",
    "    line = np.ones((H, 10, 3), dtype=np.uint8) * 128\n",
    "    composite = np.concatenate([green_rgb, line, mask_rgb, line, pred_rgb], axis=1)\n",
    "    out_name = os.path.splitext(os.path.basename(img_path))[0] + \".png\"\n",
    "    plt.imsave(os.path.join(RESULT_DIRECTORY, out_name), composite)\n",
    "\n",
    "# Print average metrics\n",
    "num = len(test_images)\n",
    "j, f1, r, p, a = [m / num for m in metrics_score]\n",
    "print(f\"\\nTest Set Metrics:\")\n",
    "print(f\"  Jaccard:   {j:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")\n",
    "print(f\"  Recall:    {r:.4f}\")\n",
    "print(f\"  Precision: {p:.4f}\")\n",
    "print(f\"  Accuracy:  {a:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080bd48-634b-443b-aa93-36bff8600fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
