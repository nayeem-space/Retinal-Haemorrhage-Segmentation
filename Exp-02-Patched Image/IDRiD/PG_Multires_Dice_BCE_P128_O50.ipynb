{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89b0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from operator import add\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch / Batch Variables \n",
    "PATCH_SIZE = 128    # 32, 64, 128\n",
    "OVERLAP    = 0.5   # 0.0, 0.25, 0.5, 0.8\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 50\n",
    "PATIENCE = 13\n",
    "\n",
    "MODEL_NAME       = f\"G_MultiRes_UNet_Tversky_P{PATCH_SIZE}_O{int(OVERLAP*100)}\"\n",
    "MODEL_DIRECTORY  = f\"G_Model_MultiRes_UNet_Tversky_P{PATCH_SIZE}_O{int(OVERLAP*100)}\"\n",
    "RESULT_DIRECTORY = f\"G_Results_MultiRes_UNet_Tversky_P{PATCH_SIZE}_O{int(OVERLAP*100)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacd1295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    mins = int(elapsed_time / 60)\n",
    "    secs = int(elapsed_time - mins*60)\n",
    "    return mins, secs\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy() > 0.5\n",
    "    y_pred = torch.sigmoid(y_pred).cpu().numpy() > 0.5\n",
    "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
    "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
    "    return [\n",
    "        jaccard_score(y_true, y_pred, zero_division=0),\n",
    "        f1_score(y_true, y_pred, zero_division=0),\n",
    "        recall_score(y_true, y_pred, zero_division=0),\n",
    "        precision_score(y_true, y_pred, zero_division=0),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return np.concatenate([mask]*3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd8a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patching Dataset  \n",
    "class PatchRetinalDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, patch_size, overlap):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path  = masks_path\n",
    "        self.patch_size  = patch_size\n",
    "        self.stride      = int(patch_size * (1 - overlap))\n",
    "        self.n_images    = len(images_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.images_path[idx], cv2.IMREAD_COLOR)[:,:,1] / 255.0\n",
    "        msk = cv2.imread(self.masks_path[idx],  cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "        H, W = img.shape\n",
    "\n",
    "        patches, mask_patches = [], []\n",
    "        for y in range(0, H - self.patch_size + 1, self.stride):\n",
    "            for x in range(0, W - self.patch_size + 1, self.stride):\n",
    "                p = img[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                m = msk[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                patches.append(torch.from_numpy(p[None].astype(np.float32)))\n",
    "                mask_patches.append(torch.from_numpy(m[None].astype(np.float32)))\n",
    "\n",
    "        return torch.stack(patches, dim=0), torch.stack(mask_patches, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bee75a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.smooth = smooth\n",
    "        self.bce_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # BCE component (stable, with logits)\n",
    "        bce_loss = self.bce_fn(logits, targets)\n",
    "\n",
    "        # Dice component (per-sample)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        batch_size = probs.shape[0]\n",
    "        dice_losses = []\n",
    "        for i in range(batch_size):\n",
    "            p = probs[i].view(-1)\n",
    "            g = targets[i].view(-1)\n",
    "            inter = (p * g).sum()\n",
    "            dice = 1 - (2*inter + self.smooth) / (p.sum() + g.sum() + self.smooth)\n",
    "            dice_losses.append(dice)\n",
    "        dice_loss = torch.stack(dice_losses).mean()\n",
    "\n",
    "        return self.alpha * dice_loss + (1 - self.alpha) * bce_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ddfb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel_size=3, padding=1, act=True):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=kernel_size, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        ]\n",
    "        if act == True:\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class multires_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c, alpha=1.67):\n",
    "        super().__init__()\n",
    "\n",
    "        W = out_c * alpha\n",
    "        self.c1 = conv_block(in_c, int(W*0.167))\n",
    "        self.c2 = conv_block(int(W*0.167), int(W*0.333))\n",
    "        self.c3 = conv_block(int(W*0.333), int(W*0.5))\n",
    "\n",
    "        nf = int(W*0.167) + int(W*0.333) + int(W*0.5)\n",
    "        self.b1 = nn.BatchNorm2d(nf)\n",
    "        self.c4 = conv_block(in_c, nf)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.b2 = nn.BatchNorm2d(nf)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x\n",
    "        x1 = self.c1(x0)\n",
    "        x2 = self.c2(x1)\n",
    "        x3 = self.c3(x2)\n",
    "        xc = torch.cat([x1, x2, x3], dim=1)\n",
    "        xc = self.b1(xc)\n",
    "\n",
    "        sc = self.c4(x0)\n",
    "        x = self.relu(xc + sc)\n",
    "        x = self.b2(x)\n",
    "        return x\n",
    "\n",
    "class res_path_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c1 = conv_block(in_c, out_c, act=False)\n",
    "        self.s1 = conv_block(in_c, out_c, kernel_size=1, padding=0, act=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.bn = nn.BatchNorm2d(out_c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.c1(x)\n",
    "        s1 = self.s1(x)\n",
    "        x = self.relu(x1 + s1)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "class res_path(nn.Module):\n",
    "    def __init__(self, in_c, out_c, length):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        for i in range(length):\n",
    "            layers.append(res_path_block(in_c, out_c))\n",
    "            in_c = out_c\n",
    "\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "def cal_nf(ch, alpha=1.67):\n",
    "    W = ch * alpha\n",
    "    return int(W*0.167) + int(W*0.333) + int(W*0.5)\n",
    "\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c, length):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c1 = multires_block(in_c, out_c)\n",
    "        nf = cal_nf(out_c)\n",
    "        self.s1 = res_path(nf, out_c, length)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c1(x)\n",
    "        s = self.s1(x)\n",
    "        p = self.pool(x)\n",
    "        return s, p\n",
    "\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c1 = nn.ConvTranspose2d(in_c[0], out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.c2 = multires_block(out_c+in_c[1], out_c)\n",
    "\n",
    "    def forward(self, x, s):\n",
    "        x = self.c1(x)\n",
    "        x = torch.cat([x, s], dim=1)\n",
    "        x = self.c2(x)\n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder \"\"\"\n",
    "        self.e1 = encoder_block(1, 32, 4)\n",
    "        self.e2 = encoder_block(cal_nf(32), 64, 3)\n",
    "        self.e3 = encoder_block(cal_nf(64), 128, 2)\n",
    "        self.e4 = encoder_block(cal_nf(128), 256, 1)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        self.b1 = multires_block(cal_nf(256), 512)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block([cal_nf(512), 256], 256)\n",
    "        self.d2 = decoder_block([cal_nf(256), 128], 128)\n",
    "        self.d3 = decoder_block([cal_nf(128), 64], 64)\n",
    "        self.d4 = decoder_block([cal_nf(64), 32], 32)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        self.output = nn.Conv2d(cal_nf(32), 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s1, p1 = self.e1(x)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        b1 = self.b1(p4)\n",
    "\n",
    "        d1 = self.d1(b1, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "\n",
    "        output = self.output(d4)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c059fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeding(42)\n",
    "create_directory(MODEL_DIRECTORY)\n",
    "create_directory(RESULT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "647e291b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nayeem\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load file lists\n",
    "train_images = sorted(glob(\"./final_dataset/train/images/*\"))\n",
    "train_masks  = sorted(glob(\"./final_dataset/train/masks/*\"))\n",
    "test_images  = sorted(glob(\"./final_dataset/test/images/*\"))\n",
    "test_masks   = sorted(glob(\"./final_dataset/test/masks/*\"))\n",
    "\n",
    "# build datasets\n",
    "train_ds_full = PatchRetinalDataset(train_images, train_masks, PATCH_SIZE, OVERLAP)\n",
    "test_ds_full  = PatchRetinalDataset(test_images, test_masks, PATCH_SIZE, OVERLAP)\n",
    "\n",
    "# split test into val/test\n",
    "n_val = len(test_ds_full)//2\n",
    "n_test= len(test_ds_full)-n_val\n",
    "valid_ds, test_ds = random_split(test_ds_full, [n_val, n_test])\n",
    "\n",
    "# flatten into patches\n",
    "def flatten(ds):\n",
    "    xs, ys = [], []\n",
    "    for xp, yp in ds:\n",
    "        xs.append(xp); ys.append(yp)\n",
    "    return TensorDataset(torch.cat(xs,0), torch.cat(ys,0))\n",
    "\n",
    "train_ds = flatten(train_ds_full)\n",
    "valid_ds = flatten(valid_ds)\n",
    "\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model     = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "loss_fn   = DiceBCELoss()\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# standard train/eval fns\n",
    "def train_epoch(model, loader):\n",
    "    model.train(); total=0\n",
    "    for x,y in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(x), y)\n",
    "        loss.backward(); optimizer.step()\n",
    "        total += loss.item()\n",
    "    return total/len(loader)\n",
    "\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval(); total=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm(loader, desc=\"Valid\", leave=False):\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            total += loss_fn(model(x), y).item()\n",
    "    return total/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9080927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/50 | 3m 42s\n",
      "Train: 0.7692 | Valid: 0.6838\n",
      "Acc:0.9792 F1:0.3014 Dice:0.3564 Rec:0.4585 Prec:0.2915 Jac:0.1957\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/50 | 3m 41s\n",
      "Train: 0.6006 | Valid: 0.5453\n",
      "Acc:0.9837 F1:0.3493 Dice:0.3870 Rec:0.4172 Prec:0.3609 Jac:0.2299\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/50 | 3m 41s\n",
      "Train: 0.4948 | Valid: 0.4889\n",
      "Acc:0.9844 F1:0.3655 Dice:0.3997 Rec:0.4290 Prec:0.3741 Jac:0.2444\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/50 | 3m 41s\n",
      "Train: 0.4279 | Valid: 0.4553\n",
      "Acc:0.9833 F1:0.3651 Dice:0.4083 Rec:0.4836 Prec:0.3533 Jac:0.2423\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/50 | 3m 41s\n",
      "Train: 0.3705 | Valid: 0.4640\n",
      "Acc:0.9858 F1:0.3528 Dice:0.3866 Rec:0.3254 Prec:0.4760 Jac:0.2314\n",
      "No improvement for 1/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/50 | 3m 41s\n",
      "Train: 0.3344 | Valid: 0.4441\n",
      "Acc:0.9851 F1:0.3875 Dice:0.4140 Rec:0.4542 Prec:0.3803 Jac:0.2637\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07/50 | 3m 41s\n",
      "Train: 0.3145 | Valid: 0.4437\n",
      "Acc:0.9866 F1:0.3963 Dice:0.4191 Rec:0.4009 Prec:0.4390 Jac:0.2727\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08/50 | 3m 41s\n",
      "Train: 0.3001 | Valid: 0.4565\n",
      "Acc:0.9863 F1:0.3924 Dice:0.4168 Rec:0.3520 Prec:0.5108 Jac:0.2656\n",
      "No improvement for 1/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09/50 | 3m 41s\n",
      "Train: 0.2918 | Valid: 0.4488\n",
      "Acc:0.9862 F1:0.3829 Dice:0.4031 Rec:0.3515 Prec:0.4725 Jac:0.2592\n",
      "No improvement for 2/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | 3m 41s\n",
      "Train: 0.2840 | Valid: 0.4441\n",
      "Acc:0.9859 F1:0.3844 Dice:0.4104 Rec:0.4078 Prec:0.4130 Jac:0.2592\n",
      "No improvement for 3/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | 3m 41s\n",
      "Train: 0.2766 | Valid: 0.4429\n",
      "Acc:0.9866 F1:0.3953 Dice:0.4213 Rec:0.4055 Prec:0.4383 Jac:0.2688\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | 3m 41s\n",
      "Train: 0.2732 | Valid: 0.4429\n",
      "Acc:0.9864 F1:0.3963 Dice:0.4203 Rec:0.4102 Prec:0.4309 Jac:0.2724\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | 3m 41s\n",
      "Train: 0.2664 | Valid: 0.4495\n",
      "Acc:0.9865 F1:0.3871 Dice:0.4119 Rec:0.3705 Prec:0.4638 Jac:0.2629\n",
      "No improvement for 1/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | 3m 41s\n",
      "Train: 0.2628 | Valid: 0.4427\n",
      "Acc:0.9867 F1:0.3954 Dice:0.4150 Rec:0.3892 Prec:0.4445 Jac:0.2730\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | 3m 41s\n",
      "Train: 0.2587 | Valid: 0.4499\n",
      "Acc:0.9865 F1:0.3968 Dice:0.4242 Rec:0.3815 Prec:0.4777 Jac:0.2662\n",
      "No improvement for 1/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | 3m 41s\n",
      "Train: 0.2566 | Valid: 0.4444\n",
      "Acc:0.9862 F1:0.3771 Dice:0.3952 Rec:0.3841 Prec:0.4069 Jac:0.2568\n",
      "No improvement for 2/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | 3m 41s\n",
      "Train: 0.2543 | Valid: 0.4482\n",
      "Acc:0.9867 F1:0.3777 Dice:0.3985 Rec:0.3441 Prec:0.4733 Jac:0.2543\n",
      "No improvement for 3/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | 3m 41s\n",
      "Train: 0.2499 | Valid: 0.4576\n",
      "Acc:0.9865 F1:0.3709 Dice:0.3955 Rec:0.3404 Prec:0.4719 Jac:0.2476\n",
      "No improvement for 4/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | 3m 41s\n",
      "Train: 0.2465 | Valid: 0.4582\n",
      "Acc:0.9866 F1:0.3647 Dice:0.3880 Rec:0.3203 Prec:0.4920 Jac:0.2431\n",
      "No improvement for 5/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | 3m 41s\n",
      "Train: 0.2447 | Valid: 0.4576\n",
      "Acc:0.9866 F1:0.3692 Dice:0.3908 Rec:0.3369 Prec:0.4651 Jac:0.2482\n",
      "No improvement for 6/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | 3m 41s\n",
      "Train: 0.2402 | Valid: 0.4567\n",
      "Acc:0.9867 F1:0.3781 Dice:0.4045 Rec:0.3467 Prec:0.4853 Jac:0.2549\n",
      "No improvement for 7/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | 3m 41s\n",
      "Train: 0.2370 | Valid: 0.4587\n",
      "Acc:0.9867 F1:0.3745 Dice:0.3991 Rec:0.3354 Prec:0.4927 Jac:0.2520\n",
      "No improvement for 8/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | 3m 41s\n",
      "Train: 0.2354 | Valid: 0.4576\n",
      "Acc:0.9867 F1:0.3791 Dice:0.4034 Rec:0.3396 Prec:0.4967 Jac:0.2553\n",
      "No improvement for 9/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | 3m 41s\n",
      "Train: 0.2343 | Valid: 0.4621\n",
      "Acc:0.9866 F1:0.3635 Dice:0.3882 Rec:0.3206 Prec:0.4919 Jac:0.2439\n",
      "No improvement for 10/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | 3m 41s\n",
      "Train: 0.2336 | Valid: 0.4580\n",
      "Acc:0.9867 F1:0.3768 Dice:0.4012 Rec:0.3396 Prec:0.4901 Jac:0.2529\n",
      "No improvement for 11/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | 3m 41s\n",
      "Train: 0.2327 | Valid: 0.4606\n",
      "Acc:0.9866 F1:0.3694 Dice:0.3933 Rec:0.3322 Prec:0.4819 Jac:0.2476\n",
      "No improvement for 12/13 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | 3m 41s\n",
      "Train: 0.2319 | Valid: 0.4603\n",
      "Acc:0.9866 F1:0.3695 Dice:0.3930 Rec:0.3302 Prec:0.4854 Jac:0.2475\n",
      "No improvement for 13/13 epochs\n",
      "Stopping early after 13 epochs without improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Training Loop \n",
    "early_stop_counter = 0\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "for epoch in range(EPOCH):\n",
    "    start = time.time()\n",
    "    tr_loss = train_epoch(model, train_loader)\n",
    "    va_loss = eval_epoch(model, valid_loader)\n",
    "    scheduler.step(va_loss)\n",
    "\n",
    "    # compute metrics on validation patches\n",
    "    model.eval()\n",
    "    mets = [0.0]*5\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm(valid_loader, desc=\"Val Metrics\", leave=False):\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            mets = list(map(add, mets, calculate_metrics(y, model(x))))\n",
    "    mets = [m/len(valid_loader) for m in mets]\n",
    "    j,f1,r,p,a = mets\n",
    "    dice = (2*p*r)/(p+r+1e-7)\n",
    "    mins, secs = epoch_time(start, time.time())\n",
    "    print(f\"Epoch {epoch+1:02}/{EPOCH} | {mins}m {secs}s\")\n",
    "    print(f\"Train: {tr_loss:.4f} | Valid: {va_loss:.4f}\")\n",
    "    print(f\"Acc:{a:.4f} F1:{f1:.4f} Dice:{dice:.4f} Rec:{r:.4f} Prec:{p:.4f} Jac:{j:.4f}\")\n",
    "\n",
    "    if va_loss < best_loss:\n",
    "        best_loss = va_loss\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIRECTORY, MODEL_NAME+\".pth\"))\n",
    "        print(\"Saved best model\")\n",
    "        early_stop_counter = 0\n",
    "   \n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"No improvement for {early_stop_counter}/{PATIENCE} epochs\")\n",
    "\n",
    "    if early_stop_counter >= PATIENCE:\n",
    "        print(f\"Stopping early after {PATIENCE} epochs without improvement.\")\n",
    "        break\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfd403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 14/14 [00:10<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics over Test images:\n",
      "  Jaccard:  0.3867\n",
      "  F1 Score: 0.5475\n",
      "  Recall:   0.5417\n",
      "  Precision:0.6043\n",
      "  Accuracy: 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing & Final Metrics \n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIRECTORY, MODEL_NAME + \".pth\"), map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# accumulators for final metrics\n",
    "metrics_score = [0.0] * 5\n",
    "\n",
    "# get only the held-out test indices\n",
    "test_indices = test_ds.indices\n",
    "\n",
    "for idx in tqdm(test_indices, total=len(test_indices), desc=\"Testing\"):\n",
    "    img_path = test_images[idx]\n",
    "    msk_path = test_masks[idx]\n",
    "\n",
    "    # load full-size\n",
    "    green = cv2.imread(img_path,    cv2.IMREAD_COLOR)[:,:,1] / 255.0\n",
    "    mask  = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)  / 255.0\n",
    "    H, W  = green.shape\n",
    "\n",
    "    # sliding-window recon\n",
    "    pred_accum  = np.zeros((H, W), dtype=np.float32)\n",
    "    count_accum = np.zeros((H, W), dtype=np.float32)\n",
    "    stride = int(PATCH_SIZE * (1 - OVERLAP))\n",
    "\n",
    "    for y in range(0, H - PATCH_SIZE + 1, stride):\n",
    "        for x in range(0, W - PATCH_SIZE + 1, stride):\n",
    "            patch = torch.from_numpy(\n",
    "                green[y:y+PATCH_SIZE, x:x+PATCH_SIZE][None,None].astype(np.float32)\n",
    "            ).to(device)\n",
    "            with torch.no_grad():\n",
    "                out = torch.sigmoid(model(patch))[0,0].cpu().numpy()\n",
    "            pred_accum[y:y+PATCH_SIZE, x:x+PATCH_SIZE]  += out\n",
    "            count_accum[y:y+PATCH_SIZE, x:x+PATCH_SIZE] += 1.0\n",
    "\n",
    "    # final binary mask\n",
    "    pred_avg = pred_accum / np.maximum(count_accum, 1e-6)\n",
    "    pred_bin = (pred_avg > 0.5).astype(np.uint8)\n",
    "\n",
    "    # compute this image's metrics\n",
    "    y_true = mask.reshape(-1) > 0.5\n",
    "    y_pred = pred_bin.reshape(-1) > 0.5\n",
    "    mets = [\n",
    "        jaccard_score(y_true, y_pred, zero_division=0),\n",
    "        f1_score(y_true, y_pred, zero_division=0),\n",
    "        recall_score(y_true, y_pred, zero_division=0),\n",
    "        precision_score(y_true, y_pred, zero_division=0),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "    metrics_score = list(map(add, metrics_score, mets))\n",
    "\n",
    "    # build & save composite as before\n",
    "    green_rgb = np.stack([ (green*255).astype(np.uint8) ]*3, axis=-1)\n",
    "    mask_rgb  = mask_parse((mask*255).astype(np.uint8))\n",
    "    pred_rgb  = mask_parse((pred_bin*255).astype(np.uint8))\n",
    "    line = np.ones((H,10,3),dtype=np.uint8)*128\n",
    "    composite = np.concatenate([green_rgb, line, mask_rgb, line, pred_rgb], axis=1)\n",
    "    out_name = os.path.splitext(os.path.basename(img_path))[0] + \".png\"\n",
    "    plt.imsave(os.path.join(RESULT_DIRECTORY, out_name), composite)\n",
    "\n",
    "# average and print final metrics over the held-out test subset\n",
    "num = len(test_indices)\n",
    "j, f1, r, p, a = [m/num for m in metrics_score]\n",
    "print(f\"\\nTest Set Metrics over Test images:\")\n",
    "print(f\"  Jaccard:  {j:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Recall:   {r:.4f}\")\n",
    "print(f\"  Precision:{p:.4f}\")\n",
    "print(f\"  Accuracy: {a:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
