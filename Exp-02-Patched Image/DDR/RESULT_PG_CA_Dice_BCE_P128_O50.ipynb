{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89b0d56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T20:26:10.846246Z",
     "iopub.status.busy": "2025-05-18T20:26:10.845936Z",
     "iopub.status.idle": "2025-05-18T20:27:43.160954Z",
     "shell.execute_reply": "2025-05-18T20:27:43.159471Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from operator import add\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d90f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T20:27:43.165435Z",
     "iopub.status.busy": "2025-05-18T20:27:43.164999Z",
     "iopub.status.idle": "2025-05-18T20:27:43.170991Z",
     "shell.execute_reply": "2025-05-18T20:27:43.169942Z"
    }
   },
   "outputs": [],
   "source": [
    "# Patch / Batch Variables \n",
    "PATCH_SIZE = 128    # 32, 64, 128\n",
    "OVERLAP    = 0.5   # 0.0, 0.25, 0.5, 0.8\n",
    "BATCH_SIZE = 32\n",
    "EPOCH = 40\n",
    "PATIENCE = 10\n",
    "\n",
    "MODEL_NAME       = f\"G_Custom_Attention_Dice_BCE_P{PATCH_SIZE}_O{int(OVERLAP*100)}\"\n",
    "MODEL_DIRECTORY  = f\"G_Model_Custom_Attention_Dice_BCE_P{PATCH_SIZE}_O{int(OVERLAP*100)}\"\n",
    "RESULT_DIRECTORY = f\"G_Results_Custom_Attention_Dice_BCE_P{PATCH_SIZE}_O{int(OVERLAP*100)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacd1295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T20:27:43.174498Z",
     "iopub.status.busy": "2025-05-18T20:27:43.174253Z",
     "iopub.status.idle": "2025-05-18T20:27:43.183568Z",
     "shell.execute_reply": "2025-05-18T20:27:43.182749Z"
    }
   },
   "outputs": [],
   "source": [
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    mins = int(elapsed_time / 60)\n",
    "    secs = int(elapsed_time - mins*60)\n",
    "    return mins, secs\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    y_true = y_true.cpu().numpy() > 0.5\n",
    "    y_pred = torch.sigmoid(y_pred).cpu().numpy() > 0.5\n",
    "    y_true = y_true.astype(np.uint8).reshape(-1)\n",
    "    y_pred = y_pred.astype(np.uint8).reshape(-1)\n",
    "    return [\n",
    "        jaccard_score(y_true, y_pred, zero_division=0),\n",
    "        f1_score(y_true, y_pred, zero_division=0),\n",
    "        recall_score(y_true, y_pred, zero_division=0),\n",
    "        precision_score(y_true, y_pred, zero_division=0),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "\n",
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    return np.concatenate([mask]*3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dd8a01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T20:27:43.187397Z",
     "iopub.status.busy": "2025-05-18T20:27:43.186963Z",
     "iopub.status.idle": "2025-05-18T20:27:43.194580Z",
     "shell.execute_reply": "2025-05-18T20:27:43.193961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Patching Dataset \n",
    "class PatchRetinalDataset(Dataset):\n",
    "    def __init__(self, images_path, masks_path, patch_size, overlap):\n",
    "        self.images_path = images_path\n",
    "        self.masks_path  = masks_path\n",
    "        self.patch_size  = patch_size\n",
    "        self.stride      = int(patch_size * (1 - overlap))\n",
    "        self.n_images    = len(images_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.images_path[idx], cv2.IMREAD_COLOR)[:,:,1] / 255.0\n",
    "        msk = cv2.imread(self.masks_path[idx],  cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "        H, W = img.shape\n",
    "\n",
    "        patches, mask_patches = [], []\n",
    "        for y in range(0, H - self.patch_size + 1, self.stride):\n",
    "            for x in range(0, W - self.patch_size + 1, self.stride):\n",
    "                p = img[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                m = msk[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                patches.append(torch.from_numpy(p[None].astype(np.float32)))\n",
    "                mask_patches.append(torch.from_numpy(m[None].astype(np.float32)))\n",
    "\n",
    "        return torch.stack(patches, dim=0), torch.stack(mask_patches, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bee75a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T20:27:43.197444Z",
     "iopub.status.busy": "2025-05-18T20:27:43.197110Z",
     "iopub.status.idle": "2025-05-18T20:27:43.202478Z",
     "shell.execute_reply": "2025-05-18T20:27:43.201988Z"
    }
   },
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.smooth = smooth\n",
    "        self.bce_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # BCE component (stable, with logits)\n",
    "        bce_loss = self.bce_fn(logits, targets)\n",
    "\n",
    "        # Dice component (per-sample)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        batch_size = probs.shape[0]\n",
    "        dice_losses = []\n",
    "        for i in range(batch_size):\n",
    "            p = probs[i].view(-1)\n",
    "            g = targets[i].view(-1)\n",
    "            inter = (p * g).sum()\n",
    "            dice = 1 - (2*inter + self.smooth) / (p.sum() + g.sum() + self.smooth)\n",
    "            dice_losses.append(dice)\n",
    "        dice_loss = torch.stack(dice_losses).mean()\n",
    "\n",
    "        return self.alpha * dice_loss + (1 - self.alpha) * bce_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ddfb182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T20:27:43.205067Z",
     "iopub.status.busy": "2025-05-18T20:27:43.204708Z",
     "iopub.status.idle": "2025-05-18T20:27:43.215782Z",
     "shell.execute_reply": "2025-05-18T20:27:43.215561Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Additive attention block for U-Net skip connections.\"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        # W_g: gating signal transform\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # W_x: skip connection transform\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # psi: attention coefficient\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        # g: gating signal (from decoder), x: skip features (from encoder)\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi  # apply attention\n",
    "\n",
    "\n",
    "class TripleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 3 times.\"\"\"\n",
    "    def __init__(self, in_c, mid1_c, mid2_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid1_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid1_c)\n",
    "        self.conv2 = nn.Conv2d(mid1_c, mid2_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(mid2_c)\n",
    "        self.conv3 = nn.Conv2d(mid2_c, out_c, 3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 2 times.\"\"\"\n",
    "    def __init__(self, in_c, mid_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid_c)\n",
    "        self.conv2 = nn.Conv2d(mid_c, out_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net with attention gates on skip connections and additional subsampling concat.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.down1 = TripleConv(1, 32, 32, 64)\n",
    "        self.down2 = TripleConv(64, 64, 64, 128)\n",
    "        self.down3 = DoubleConv(128, 128, 256)\n",
    "        self.down4 = DoubleConv(256, 256, 256)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(256, 512, 256)\n",
    "\n",
    "        # Decoder up and conv\n",
    "        self.up4  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec4 = DoubleConv(256+256, 256, 256)\n",
    "        self.up3  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec3 = DoubleConv(256+256, 128, 128)\n",
    "        self.up2  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec2 = TripleConv(128+128, 64, 64, 64)\n",
    "        self.up1  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec1 = TripleConv(64+64, 32, 32, 32)\n",
    "\n",
    "        # Attention blocks for skip connections\n",
    "        self.att4 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att3 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att2 = AttentionBlock(F_g=128, F_l=128, F_int=64)\n",
    "        self.att1 = AttentionBlock(F_g=64,  F_l=64,  F_int=32)\n",
    "\n",
    "        # Final subsample, concat and output\n",
    "        self.final_pool       = nn.MaxPool2d(2, 2)\n",
    "        self.final_upsample   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.out_conv         = nn.Conv2d(33, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_image = x\n",
    "        # Encoder\n",
    "        x1  = self.down1(x)\n",
    "        x1p = self.pool(x1)\n",
    "        x2  = self.down2(x1p)\n",
    "        x2p = self.pool(x2)\n",
    "        x3  = self.down3(x2p)\n",
    "        x3p = self.pool(x3)\n",
    "        x4  = self.down4(x3p)\n",
    "        x4p = self.pool(x4)\n",
    "\n",
    "        # Bottleneck\n",
    "        xb  = self.bottleneck(x4p)\n",
    "\n",
    "        # Decoder + Attention\n",
    "        d4  = self.up4(xb)\n",
    "        x4a = self.att4(g=d4, x=x4)\n",
    "        d4  = torch.cat([x4a, d4], dim=1)\n",
    "        d4  = self.dec4(d4)\n",
    "\n",
    "        d3  = self.up3(d4)\n",
    "        x3a = self.att3(g=d3, x=x3)\n",
    "        d3  = torch.cat([x3a, d3], dim=1)\n",
    "        d3  = self.dec3(d3)\n",
    "\n",
    "        d2  = self.up2(d3)\n",
    "        x2a = self.att2(g=d2, x=x2)\n",
    "        d2  = torch.cat([x2a, d2], dim=1)\n",
    "        d2  = self.dec2(d2)\n",
    "\n",
    "        d1  = self.up1(d2)\n",
    "        x1a = self.att1(g=d1, x=x1)\n",
    "        d1  = torch.cat([x1a, d1], dim=1)\n",
    "        d1  = self.dec1(d1)\n",
    "\n",
    "        # Additional subsampling & concatenation\n",
    "        d1s = self.final_pool(d1)\n",
    "        ins = self.final_pool(input_image)\n",
    "        cat = torch.cat([d1s, ins], dim=1)\n",
    "        out = self.final_upsample(cat)\n",
    "        out = self.out_conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c059fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T20:27:43.216945Z",
     "iopub.status.busy": "2025-05-18T20:27:43.216777Z",
     "iopub.status.idle": "2025-05-18T20:27:43.309687Z",
     "shell.execute_reply": "2025-05-18T20:27:43.308518Z"
    }
   },
   "outputs": [],
   "source": [
    "seeding(42)\n",
    "create_directory(MODEL_DIRECTORY)\n",
    "create_directory(RESULT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "647e291b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T20:27:43.313169Z",
     "iopub.status.busy": "2025-05-18T20:27:43.312932Z",
     "iopub.status.idle": "2025-05-18T20:29:48.602904Z",
     "shell.execute_reply": "2025-05-18T20:29:48.601699Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/HS401/in00199/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load file lists\n",
    "train_images = sorted(glob(\"../final_dataset/train/images/*\"))\n",
    "train_masks  = sorted(glob(\"../final_dataset/train/masks/*\"))\n",
    "test_images  = sorted(glob(\"../final_dataset/test/images/*\"))\n",
    "test_masks   = sorted(glob(\"../final_dataset/test/masks/*\"))\n",
    "\n",
    "# build datasets\n",
    "train_ds_full = PatchRetinalDataset(train_images, train_masks, PATCH_SIZE, OVERLAP)\n",
    "test_ds_full  = PatchRetinalDataset(test_images, test_masks, PATCH_SIZE, OVERLAP)\n",
    "\n",
    "# split test into val/test\n",
    "n_val = len(test_ds_full)//2\n",
    "n_test= len(test_ds_full)-n_val\n",
    "valid_ds, test_ds = random_split(test_ds_full, [n_val, n_test])\n",
    "\n",
    "# flatten into patches\n",
    "def flatten(ds):\n",
    "    xs, ys = [], []\n",
    "    for xp, yp in ds:\n",
    "        xs.append(xp); ys.append(yp)\n",
    "    return TensorDataset(torch.cat(xs,0), torch.cat(ys,0))\n",
    "\n",
    "train_ds = flatten(train_ds_full)\n",
    "valid_ds = flatten(valid_ds)\n",
    "\n",
    "device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model     = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "loss_fn   = DiceBCELoss()\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# standard train/eval fns\n",
    "def train_epoch(model, loader):\n",
    "    model.train(); total=0\n",
    "    for x,y in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(model(x), y)\n",
    "        loss.backward(); optimizer.step()\n",
    "        total += loss.item()\n",
    "    return total/len(loader)\n",
    "\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval(); total=0\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm(loader, desc=\"Valid\", leave=False):\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            total += loss_fn(model(x), y).item()\n",
    "    return total/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9080927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T20:29:48.720338Z",
     "iopub.status.busy": "2025-05-18T20:29:48.719815Z",
     "iopub.status.idle": "2025-05-19T01:18:48.769156Z",
     "shell.execute_reply": "2025-05-19T01:18:48.768965Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/40 | 21m 5s\n",
      "Train: 0.4742 | Valid: 0.4322\n",
      "Acc:0.9905 F1:0.3889 Dice:0.4528 Rec:0.4463 Prec:0.4596 Jac:0.2619\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/40 | 20m 37s\n",
      "Train: 0.4335 | Valid: 0.4311\n",
      "Acc:0.9917 F1:0.4063 Dice:0.4620 Rec:0.3998 Prec:0.5472 Jac:0.2762\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/40 | 20m 37s\n",
      "Train: 0.4253 | Valid: 0.4294\n",
      "Acc:0.9909 F1:0.3991 Dice:0.4628 Rec:0.4415 Prec:0.4864 Jac:0.2698\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/40 | 20m 36s\n",
      "Train: 0.4195 | Valid: 0.4283\n",
      "Acc:0.9909 F1:0.4236 Dice:0.4883 Rec:0.4593 Prec:0.5212 Jac:0.2909\n",
      "Saved best model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/40 | 20m 37s\n",
      "Train: 0.4151 | Valid: 0.4332\n",
      "Acc:0.9904 F1:0.4113 Dice:0.4764 Rec:0.4198 Prec:0.5505 Jac:0.2821\n",
      "No improvement for 1/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/40 | 20m 36s\n",
      "Train: 0.4114 | Valid: 0.4294\n",
      "Acc:0.9886 F1:0.4096 Dice:0.4738 Rec:0.4625 Prec:0.4856 Jac:0.2788\n",
      "No improvement for 2/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07/40 | 20m 36s\n",
      "Train: 0.4083 | Valid: 0.4354\n",
      "Acc:0.9917 F1:0.4147 Dice:0.4761 Rec:0.4132 Prec:0.5616 Jac:0.2845\n",
      "No improvement for 3/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08/40 | 20m 36s\n",
      "Train: 0.4055 | Valid: 0.4360\n",
      "Acc:0.9896 F1:0.3947 Dice:0.4608 Rec:0.4418 Prec:0.4815 Jac:0.2690\n",
      "No improvement for 4/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09/40 | 20m 36s\n",
      "Train: 0.4032 | Valid: 0.4401\n",
      "Acc:0.9901 F1:0.4053 Dice:0.4643 Rec:0.4055 Prec:0.5432 Jac:0.2764\n",
      "No improvement for 5/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40 | 20m 36s\n",
      "Train: 0.4010 | Valid: 0.4386\n",
      "Acc:0.9903 F1:0.4130 Dice:0.4692 Rec:0.4267 Prec:0.5211 Jac:0.2846\n",
      "No improvement for 6/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40 | 20m 35s\n",
      "Train: 0.3951 | Valid: 0.4442\n",
      "Acc:0.9918 F1:0.4204 Dice:0.4782 Rec:0.4010 Prec:0.5923 Jac:0.2906\n",
      "No improvement for 7/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40 | 20m 35s\n",
      "Train: 0.3931 | Valid: 0.4471\n",
      "Acc:0.9917 F1:0.4174 Dice:0.4728 Rec:0.3914 Prec:0.5969 Jac:0.2880\n",
      "No improvement for 8/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40 | 20m 36s\n",
      "Train: 0.3920 | Valid: 0.4476\n",
      "Acc:0.9919 F1:0.4186 Dice:0.4755 Rec:0.3902 Prec:0.6085 Jac:0.2894\n",
      "No improvement for 9/10 epochs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40 | 20m 36s\n",
      "Train: 0.3911 | Valid: 0.4464\n",
      "Acc:0.9919 F1:0.4214 Dice:0.4775 Rec:0.4012 Prec:0.5896 Jac:0.2910\n",
      "No improvement for 10/10 epochs\n",
      "Stopping early after 10 epochs without improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "### ============== Training Loop ==============\n",
    "early_stop_counter = 0\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "for epoch in range(EPOCH):\n",
    "    start = time.time()\n",
    "    tr_loss = train_epoch(model, train_loader)\n",
    "    va_loss = eval_epoch(model, valid_loader)\n",
    "    scheduler.step(va_loss)\n",
    "\n",
    "    # compute metrics on validation patches\n",
    "    model.eval()\n",
    "    mets = [0.0]*5\n",
    "    with torch.no_grad():\n",
    "        for x,y in tqdm(valid_loader, desc=\"Val Metrics\", leave=False):\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            mets = list(map(add, mets, calculate_metrics(y, model(x))))\n",
    "    mets = [m/len(valid_loader) for m in mets]\n",
    "    j,f1,r,p,a = mets\n",
    "    dice = (2*p*r)/(p+r+1e-7)\n",
    "    mins, secs = epoch_time(start, time.time())\n",
    "    print(f\"Epoch {epoch+1:02}/{EPOCH} | {mins}m {secs}s\")\n",
    "    print(f\"Train: {tr_loss:.4f} | Valid: {va_loss:.4f}\")\n",
    "    print(f\"Acc:{a:.4f} F1:{f1:.4f} Dice:{dice:.4f} Rec:{r:.4f} Prec:{p:.4f} Jac:{j:.4f}\")\n",
    "\n",
    "    if va_loss < best_loss:\n",
    "        best_loss = va_loss\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIRECTORY, MODEL_NAME+\".pth\"))\n",
    "        print(\"Saved best model\")\n",
    "        early_stop_counter = 0\n",
    "   \n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"No improvement for {early_stop_counter}/{PATIENCE} epochs\")\n",
    "\n",
    "    if early_stop_counter >= PATIENCE:\n",
    "        print(f\"Stopping early after {PATIENCE} epochs without improvement.\")\n",
    "        break\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfd403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T01:18:48.770392Z",
     "iopub.status.busy": "2025-05-19T01:18:48.770311Z",
     "iopub.status.idle": "2025-05-19T01:19:19.258904Z",
     "shell.execute_reply": "2025-05-19T01:19:19.258614Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2587594/2903080984.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(MODEL_DIRECTORY, MODEL_NAME + \".pth\"), map_location=device))\n",
      "Testing: 100%|████████████████████████████████| 113/113 [00:30<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics over Test images:\n",
      "  Jaccard:  0.2624\n",
      "  F1 Score: 0.3805\n",
      "  Recall:   0.4372\n",
      "  Precision:0.4584\n",
      "  Accuracy: 0.9938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing & Final Metrics \n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIRECTORY, MODEL_NAME + \".pth\"), map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# accumulators for final metrics\n",
    "metrics_score = [0.0] * 5\n",
    "\n",
    "# get only the held-out test indices\n",
    "test_indices = test_ds.indices\n",
    "\n",
    "for idx in tqdm(test_indices, total=len(test_indices), desc=\"Testing\"):\n",
    "    img_path = test_images[idx]\n",
    "    msk_path = test_masks[idx]\n",
    "\n",
    "    # load full-size\n",
    "    green = cv2.imread(img_path,    cv2.IMREAD_COLOR)[:,:,1] / 255.0\n",
    "    mask  = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)  / 255.0\n",
    "    H, W  = green.shape\n",
    "\n",
    "    # sliding-window recon\n",
    "    pred_accum  = np.zeros((H, W), dtype=np.float32)\n",
    "    count_accum = np.zeros((H, W), dtype=np.float32)\n",
    "    stride = int(PATCH_SIZE * (1 - OVERLAP))\n",
    "\n",
    "    for y in range(0, H - PATCH_SIZE + 1, stride):\n",
    "        for x in range(0, W - PATCH_SIZE + 1, stride):\n",
    "            patch = torch.from_numpy(\n",
    "                green[y:y+PATCH_SIZE, x:x+PATCH_SIZE][None,None].astype(np.float32)\n",
    "            ).to(device)\n",
    "            with torch.no_grad():\n",
    "                out = torch.sigmoid(model(patch))[0,0].cpu().numpy()\n",
    "            pred_accum[y:y+PATCH_SIZE, x:x+PATCH_SIZE]  += out\n",
    "            count_accum[y:y+PATCH_SIZE, x:x+PATCH_SIZE] += 1.0\n",
    "\n",
    "    # final binary mask\n",
    "    pred_avg = pred_accum / np.maximum(count_accum, 1e-6)\n",
    "    pred_bin = (pred_avg > 0.5).astype(np.uint8)\n",
    "\n",
    "    # compute this image's metrics\n",
    "    y_true = mask.reshape(-1) > 0.5\n",
    "    y_pred = pred_bin.reshape(-1) > 0.5\n",
    "    mets = [\n",
    "        jaccard_score(y_true, y_pred, zero_division=0),\n",
    "        f1_score(y_true, y_pred, zero_division=0),\n",
    "        recall_score(y_true, y_pred, zero_division=0),\n",
    "        precision_score(y_true, y_pred, zero_division=0),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "    metrics_score = list(map(add, metrics_score, mets))\n",
    "\n",
    "    # build & save composite as before\n",
    "    green_rgb = np.stack([ (green*255).astype(np.uint8) ]*3, axis=-1)\n",
    "    mask_rgb  = mask_parse((mask*255).astype(np.uint8))\n",
    "    pred_rgb  = mask_parse((pred_bin*255).astype(np.uint8))\n",
    "    line = np.ones((H,10,3),dtype=np.uint8)*128\n",
    "    composite = np.concatenate([green_rgb, line, mask_rgb, line, pred_rgb], axis=1)\n",
    "    out_name = os.path.splitext(os.path.basename(img_path))[0] + \".png\"\n",
    "    plt.imsave(os.path.join(RESULT_DIRECTORY, out_name), composite)\n",
    "\n",
    "# average and print final metrics over the held-out test subset\n",
    "num = len(test_indices)\n",
    "j, f1, r, p, a = [m/num for m in metrics_score]\n",
    "print(f\"\\nTest Set Metrics over Test images:\")\n",
    "print(f\"  Jaccard:  {j:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"  Recall:   {r:.4f}\")\n",
    "print(f\"  Precision:{p:.4f}\")\n",
    "print(f\"  Accuracy: {a:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
