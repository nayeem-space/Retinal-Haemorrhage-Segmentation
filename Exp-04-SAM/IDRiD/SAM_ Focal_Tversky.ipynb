{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from segment_anything import sam_model_registry\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2df3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42) -> None:\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)           \n",
    "    random.seed(seed)                                 \n",
    "    np.random.seed(seed)                              \n",
    "    torch.manual_seed(seed)                           \n",
    "    torch.cuda.manual_seed(seed)                       \n",
    "    torch.cuda.manual_seed_all(seed)                   \n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    torch.backends.cudnn.deterministic = True         \n",
    "    torch.backends.cudnn.benchmark = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7dffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "\n",
    "\n",
    "dataset_path = \"./final_dataset\"               # root containing train/ & test/\n",
    "checkpoint_path = \"./sam_vit_h_4b8939.pth\"     # SAM ViT‑H checkpoint\n",
    "model_type = \"vit_h\"                           # sam encoder type\n",
    "output_dir = \"./predictions\"                   # where to save models & figs\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dde35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataset\n",
    "\n",
    "\n",
    "class RetinalHemorrhageDataset(Dataset):\n",
    "    \"\"\"Dataset loading RGB fundus images and binary masks.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir: str, split: str = \"train\", transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.images_dir = os.path.join(root_dir, split, \"images\")\n",
    "        self.masks_dir = os.path.join(root_dir, split, \"masks\")\n",
    "        self.image_files = sorted(glob.glob(os.path.join(self.images_dir, \"*.*\")))\n",
    "        self.mask_files = sorted(glob.glob(os.path.join(self.masks_dir, \"*.*\")))\n",
    "\n",
    "        assert len(self.image_files) == len(self.mask_files), (\n",
    "            f\"Number of images ({len(self.image_files)}) and masks \"\n",
    "            f\"({len(self.mask_files)}) don't match!\"\n",
    "        )\n",
    "        print(f\"Found {len(self.image_files)} samples in '{split}' split\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Image\n",
    "        img_path = self.image_files[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Failed to load image: {img_path}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Mask\n",
    "        msk_path = self.mask_files[idx]\n",
    "        msk = cv2.imread(msk_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if msk is None:\n",
    "            raise ValueError(f\"Failed to load mask: {msk_path}\")\n",
    "        msk = (msk > 0).astype(np.float32)\n",
    "\n",
    "        # To tensor\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0  # C,H,W\n",
    "        msk = torch.from_numpy(msk).unsqueeze(0).float()              # 1,H,W\n",
    "        return {\"image\": img, \"mask\": msk, \"filename\": os.path.basename(img_path)}\n",
    "\n",
    "\n",
    "# Loss Function\n",
    "\n",
    "\n",
    "\n",
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.3, beta=0.7, gamma=0.75, eps=1e-6):\n",
    "        super(FocalTverskyLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        TP = (inputs * targets).sum()\n",
    "        FP = ((1 - targets) * inputs).sum()\n",
    "        FN = (targets * (1 - inputs)).sum()\n",
    "\n",
    "        tversky = (TP + self.eps) / (TP + self.alpha * FP + self.beta * FN + self.eps)\n",
    "        focal_tversky = (1 - tversky) ** self.gamma\n",
    "\n",
    "        return focal_tversky\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# U‑Net style decoder blocks\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        self.conv = DoubleConv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNetDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch: int = 256):\n",
    "        super().__init__()\n",
    "        self.block1 = DoubleConv(in_ch, 256)\n",
    "        self.up1 = UpBlock(256, 128)\n",
    "        self.up2 = UpBlock(128, 64)\n",
    "        self.up3 = UpBlock(64, 32)\n",
    "        self.up4 = UpBlock(32, 16)\n",
    "        self.final = nn.Conv2d(16, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.up1(x)\n",
    "        x = self.up2(x)\n",
    "        x = self.up3(x)\n",
    "        x = self.up4(x)\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "# Fine‑tuner combining SAM encoder + U‑Net decoder\n",
    "\n",
    "class SAMFineTuner(nn.Module):\n",
    "    def __init__(self, checkpoint_path: str, model_type: str):\n",
    "        super().__init__()\n",
    "        print(f\"Loading SAM encoder '{model_type}' …\")\n",
    "        self.sam = sam_model_registry[model_type](checkpoint=checkpoint_path)\n",
    "        self.sam.to(device)\n",
    "        print(\"SAM encoder loaded.\")\n",
    "\n",
    "        # Freeze encoder parameters\n",
    "        for p in self.sam.image_encoder.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = UNetDecoder(in_ch=256)\n",
    "\n",
    "        # Pre‑processing helper\n",
    "        self.transform = ResizeLongestSide(self.sam.image_encoder.img_size)\n",
    "        self.pixel_mean = torch.tensor([123.675, 116.28, 103.53]).view(3, 1, 1)\n",
    "        self.pixel_std = torch.tensor([58.395, 57.12, 57.375]).view(3, 1, 1)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def preprocess_single(self, img_tensor: torch.Tensor) -> torch.Tensor:\n",
    "       \n",
    "        img_np = (img_tensor.cpu().numpy().transpose(1, 2, 0) * 255.0).astype(np.float32)\n",
    "        img_np = self.transform.apply_image(img_np)\n",
    "        t = torch.from_numpy(img_np).permute(2, 0, 1).float()\n",
    "        t = (t - self.pixel_mean) / self.pixel_std\n",
    "        return t\n",
    "\n",
    "    def forward(self, imgs: torch.Tensor):  # imgs: B,C,H,W in [0,1]\n",
    "        B, _, H, W = imgs.shape\n",
    "        processed = torch.stack([self.preprocess_single(im) for im in imgs]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            emb = self.sam.image_encoder(processed)  # B,256,h,w\n",
    "\n",
    "        dec_out = self.decoder(emb)                 # B,1,h',w'\n",
    "        dec_out = F.interpolate(dec_out, size=(H, W), mode=\"bilinear\", align_corners=False)\n",
    "        return torch.sigmoid(dec_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Metrics\n",
    "\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray, thr: float = 0.5):\n",
    "    y_pred_bin = (y_pred > thr).astype(np.uint8)\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    tp = np.sum((y_pred_bin == 1) & (y_true == 1))\n",
    "    fp = np.sum((y_pred_bin == 1) & (y_true == 0))\n",
    "    fn = np.sum((y_pred_bin == 0) & (y_true == 1))\n",
    "    tn = np.sum((y_pred_bin == 0) & (y_true == 0))\n",
    "\n",
    "    acc = (tp + tn) / (tp + fp + fn + tn + 1e-6)\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    recall = tp / (tp + fn + 1e-6)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "    iou = tp / (tp + fp + fn + 1e-6)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1_score\": f1, \"jaccard\": iou}\n",
    "\n",
    "\n",
    "# Train / Eval loops\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch}\")\n",
    "    for batch in pbar:\n",
    "        imgs = batch[\"image\"].to(device)\n",
    "        msks = batch[\"mask\"].to(device)\n",
    "        preds = model(imgs)\n",
    "        loss = criterion(preds, msks)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate(model, loader, criterion, save_preds: bool = False):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    stats = {k: [] for k in [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"jaccard\"]}\n",
    "    pbar = tqdm(loader, desc=\"Eval\")\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            imgs = batch[\"image\"].to(device)\n",
    "            msks = batch[\"mask\"].to(device)\n",
    "            fnames = batch[\"filename\"]\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, msks)\n",
    "            val_loss += loss.item()\n",
    "            preds_np = preds.cpu().numpy()\n",
    "            msks_np = msks.cpu().numpy()\n",
    "            for i in range(len(imgs)):\n",
    "                metrics = compute_metrics(msks_np[i, 0], preds_np[i, 0])\n",
    "                for k in stats:\n",
    "                    stats[k].append(metrics[k])\n",
    "                if save_preds:\n",
    "                    save_visualization(imgs[i], msks_np[i, 0], preds_np[i, 0], metrics, fnames[i])\n",
    "    avg_stats = {k: float(np.mean(v)) for k, v in stats.items()}\n",
    "    return val_loss / len(loader), avg_stats\n",
    "\n",
    "\n",
    "# Helper to save side‑by‑side visualisations\n",
    "\n",
    "\n",
    "def save_visualization(img_t, true_msk, pred_msk, metrics, fname):\n",
    "    img = (img_t.cpu().numpy().transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "    pred = (pred_msk > 0.5).astype(np.uint8) * 255\n",
    "    true = (true_msk > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(\"Image\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(true, cmap=\"gray\")\n",
    "    axes[1].set_title(\"Ground Truth\")\n",
    "    axes[1].axis(\"off\")\n",
    "    axes[2].imshow(pred, cmap=\"gray\")\n",
    "    axes[2].set_title(\"Prediction\")\n",
    "    axes[2].axis(\"off\")\n",
    "\n",
    "    txt = (\n",
    "        f\"IoU={metrics['jaccard']:.3f} | F1={metrics['f1_score']:.3f} | \"\n",
    "        f\"Prec={metrics['precision']:.3f} | Rec={metrics['recall']:.3f}\"\n",
    "    )\n",
    "    \n",
    "    # Add more space at the bottom for the text\n",
    "    plt.subplots_adjust(bottom=0.2)\n",
    "    fig.text(0.5, 0.05, txt, ha=\"center\", fontsize=10)\n",
    "\n",
    "    out_path = os.path.join(output_dir, f\"{os.path.splitext(fname)[0]}_viz.png\")\n",
    "    plt.savefig(out_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding\n",
    "seed_everything(42)\n",
    "\n",
    "# Data\n",
    "train_ds = RetinalHemorrhageDataset(dataset_path, split=\"train\")\n",
    "full_test_ds = RetinalHemorrhageDataset(dataset_path, split=\"test\")\n",
    "\n",
    "# Split test dataset into fixed 50% validation and 50% test\n",
    "val_size = len(full_test_ds) // 2\n",
    "test_size = len(full_test_ds) - val_size\n",
    "val_ds, test_ds = torch.utils.data.random_split(full_test_ds, [val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Model / loss / optim\n",
    "model = SAMFineTuner(checkpoint_path, model_type).to(device)\n",
    "criterion = FocalTverskyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"min\",\n",
    "    factor=0.1,\n",
    "    patience=4,\n",
    "    threshold=1e-4,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 477/477 [10:24<00:00,  1.31s/it, loss=0.8608]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.9607 | Val Loss: 0.9527 | IoU: 0.0235 | F1: 0.0426 | Precision: 0.0237 | Recall: 0.8766 | Accuracy: 0.4044\n",
      "New best model saved (F1: 0.0426)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 477/477 [10:00<00:00,  1.26s/it, loss=0.8793]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.9511 | Val Loss: 0.9456 | IoU: 0.0317 | F1: 0.0565 | Precision: 0.0337 | Recall: 0.8127 | Accuracy: 0.6308\n",
      "New best model saved (F1: 0.0565)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 477/477 [10:18<00:00,  1.30s/it, loss=0.9661]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.9426 | Val Loss: 0.9436 | IoU: 0.0451 | F1: 0.0815 | Precision: 0.0568 | Recall: 0.6371 | Accuracy: 0.8542\n",
      "New best model saved (F1: 0.0815)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 477/477 [10:07<00:00,  1.27s/it, loss=0.7911]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.9299 | Val Loss: 0.9295 | IoU: 0.0807 | F1: 0.1406 | Precision: 0.1101 | Recall: 0.4863 | Accuracy: 0.9492\n",
      "New best model saved (F1: 0.1406)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 477/477 [10:11<00:00,  1.28s/it, loss=0.9121]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.9138 | Val Loss: 0.9192 | IoU: 0.0861 | F1: 0.1469 | Precision: 0.1075 | Recall: 0.5549 | Accuracy: 0.9422\n",
      "New best model saved (F1: 0.1469)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 477/477 [10:14<00:00,  1.29s/it, loss=0.9506]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.8840 | Val Loss: 0.9100 | IoU: 0.0801 | F1: 0.1397 | Precision: 0.1261 | Recall: 0.4396 | Accuracy: 0.9485\n",
      "No improvement in F1 for 1 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 477/477 [10:34<00:00,  1.33s/it, loss=0.9868]\n",
      "Eval: 100%|██████████| 13/13 [00:14<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.8421 | Val Loss: 0.8679 | IoU: 0.1178 | F1: 0.1975 | Precision: 0.1657 | Recall: 0.4191 | Accuracy: 0.9683\n",
      "New best model saved (F1: 0.1975)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 477/477 [10:43<00:00,  1.35s/it, loss=0.5812]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.7893 | Val Loss: 0.8607 | IoU: 0.1219 | F1: 0.2011 | Precision: 0.1999 | Recall: 0.3077 | Accuracy: 0.9765\n",
      "New best model saved (F1: 0.2011)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 477/477 [09:56<00:00,  1.25s/it, loss=0.6088]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.7370 | Val Loss: 0.8259 | IoU: 0.1676 | F1: 0.2701 | Precision: 0.3174 | Recall: 0.2923 | Accuracy: 0.9827\n",
      "New best model saved (F1: 0.2701)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 477/477 [10:41<00:00,  1.35s/it, loss=0.6479]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.6916 | Val Loss: 0.8257 | IoU: 0.1535 | F1: 0.2523 | Precision: 0.3155 | Recall: 0.2704 | Accuracy: 0.9828\n",
      "No improvement in F1 for 1 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 477/477 [10:44<00:00,  1.35s/it, loss=0.8297]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.6547 | Val Loss: 0.8188 | IoU: 0.1460 | F1: 0.2392 | Precision: 0.2647 | Recall: 0.2839 | Accuracy: 0.9806\n",
      "No improvement in F1 for 2 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 477/477 [10:26<00:00,  1.31s/it, loss=0.7531]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.6315 | Val Loss: 0.8248 | IoU: 0.1623 | F1: 0.2646 | Precision: 0.4222 | Recall: 0.2122 | Accuracy: 0.9846\n",
      "No improvement in F1 for 3 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 477/477 [09:51<00:00,  1.24s/it, loss=0.7219]\n",
      "Eval: 100%|██████████| 13/13 [00:14<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.6130 | Val Loss: 0.8124 | IoU: 0.1506 | F1: 0.2478 | Precision: 0.3104 | Recall: 0.2575 | Accuracy: 0.9826\n",
      "No improvement in F1 for 4 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 477/477 [10:44<00:00,  1.35s/it, loss=0.5274]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 0.5886 | Val Loss: 0.8178 | IoU: 0.1546 | F1: 0.2539 | Precision: 0.3761 | Recall: 0.2253 | Accuracy: 0.9838\n",
      "No improvement in F1 for 5 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 477/477 [10:39<00:00,  1.34s/it, loss=0.4254]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 0.5816 | Val Loss: 0.7867 | IoU: 0.1878 | F1: 0.2945 | Precision: 0.4456 | Recall: 0.2532 | Accuracy: 0.9846\n",
      "New best model saved (F1: 0.2945)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 477/477 [10:02<00:00,  1.26s/it, loss=0.3820]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 0.5659 | Val Loss: 0.7779 | IoU: 0.1701 | F1: 0.2735 | Precision: 0.2902 | Recall: 0.3264 | Accuracy: 0.9816\n",
      "No improvement in F1 for 1 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 477/477 [10:35<00:00,  1.33s/it, loss=0.4221]\n",
      "Eval: 100%|██████████| 13/13 [00:14<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 0.5590 | Val Loss: 0.7772 | IoU: 0.1860 | F1: 0.2922 | Precision: 0.3788 | Recall: 0.2832 | Accuracy: 0.9838\n",
      "No improvement in F1 for 2 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 477/477 [10:44<00:00,  1.35s/it, loss=0.5690]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 0.5478 | Val Loss: 0.7630 | IoU: 0.1997 | F1: 0.3042 | Precision: 0.3876 | Recall: 0.2927 | Accuracy: 0.9838\n",
      "New best model saved (F1: 0.3042)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 477/477 [11:17<00:00,  1.42s/it, loss=0.7941]\n",
      "Eval: 100%|██████████| 13/13 [00:14<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 0.5517 | Val Loss: 0.7898 | IoU: 0.1597 | F1: 0.2597 | Precision: 0.3026 | Recall: 0.3154 | Accuracy: 0.9820\n",
      "No improvement in F1 for 1 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 477/477 [10:40<00:00,  1.34s/it, loss=0.2862]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 0.5387 | Val Loss: 0.7946 | IoU: 0.1689 | F1: 0.2744 | Precision: 0.3803 | Recall: 0.2551 | Accuracy: 0.9840\n",
      "No improvement in F1 for 2 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 477/477 [10:39<00:00,  1.34s/it, loss=0.4624]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 0.5389 | Val Loss: 0.7810 | IoU: 0.1786 | F1: 0.2737 | Precision: 0.3339 | Recall: 0.2884 | Accuracy: 0.9832\n",
      "No improvement in F1 for 3 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 477/477 [10:43<00:00,  1.35s/it, loss=0.4823]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 0.5332 | Val Loss: 0.7788 | IoU: 0.1854 | F1: 0.2881 | Precision: 0.3713 | Recall: 0.2718 | Accuracy: 0.9838\n",
      "No improvement in F1 for 4 epoch(s)\n",
      "Current lr: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 477/477 [10:58<00:00,  1.38s/it, loss=0.6493]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 0.5206 | Val Loss: 0.7677 | IoU: 0.1926 | F1: 0.3016 | Precision: 0.3920 | Recall: 0.2890 | Accuracy: 0.9849\n",
      "No improvement in F1 for 5 epoch(s)\n",
      "Current lr: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 477/477 [10:46<00:00,  1.35s/it, loss=0.6201]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 0.4909 | Val Loss: 0.7659 | IoU: 0.1985 | F1: 0.3079 | Precision: 0.4003 | Recall: 0.2837 | Accuracy: 0.9846\n",
      "New best model saved (F1: 0.3079)\n",
      "Current lr: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 477/477 [10:39<00:00,  1.34s/it, loss=0.4517]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Train Loss: 0.4782 | Val Loss: 0.7726 | IoU: 0.1906 | F1: 0.3002 | Precision: 0.3993 | Recall: 0.2783 | Accuracy: 0.9848\n",
      "No improvement in F1 for 1 epoch(s)\n",
      "Current lr: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 477/477 [10:40<00:00,  1.34s/it, loss=0.7832]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | Train Loss: 0.4708 | Val Loss: 0.7709 | IoU: 0.1940 | F1: 0.3017 | Precision: 0.4009 | Recall: 0.2772 | Accuracy: 0.9846\n",
      "No improvement in F1 for 2 epoch(s)\n",
      "Current lr: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 477/477 [10:36<00:00,  1.33s/it, loss=0.5727]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | Train Loss: 0.4656 | Val Loss: 0.7676 | IoU: 0.1994 | F1: 0.3086 | Precision: 0.4146 | Recall: 0.2755 | Accuracy: 0.9845\n",
      "New best model saved (F1: 0.3086)\n",
      "Current lr: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 477/477 [10:40<00:00,  1.34s/it, loss=0.4837]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | Train Loss: 0.4621 | Val Loss: 0.7720 | IoU: 0.1981 | F1: 0.3071 | Precision: 0.4262 | Recall: 0.2643 | Accuracy: 0.9847\n",
      "No improvement in F1 for 1 epoch(s)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 477/477 [10:39<00:00,  1.34s/it, loss=0.3347]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Train Loss: 0.4574 | Val Loss: 0.7644 | IoU: 0.2033 | F1: 0.3139 | Precision: 0.4297 | Recall: 0.2772 | Accuracy: 0.9847\n",
      "New best model saved (F1: 0.3139)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 477/477 [10:40<00:00,  1.34s/it, loss=0.5149]\n",
      "Eval: 100%|██████████| 13/13 [00:13<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Train Loss: 0.4558 | Val Loss: 0.7669 | IoU: 0.1983 | F1: 0.3061 | Precision: 0.3969 | Recall: 0.2802 | Accuracy: 0.9845\n",
      "No improvement in F1 for 1 epoch(s)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 477/477 [10:44<00:00,  1.35s/it, loss=0.7662]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Train Loss: 0.4549 | Val Loss: 0.7693 | IoU: 0.2006 | F1: 0.3091 | Precision: 0.4277 | Recall: 0.2702 | Accuracy: 0.9847\n",
      "No improvement in F1 for 2 epoch(s)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 477/477 [09:58<00:00,  1.25s/it, loss=0.2576]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | Train Loss: 0.4541 | Val Loss: 0.7743 | IoU: 0.1970 | F1: 0.3047 | Precision: 0.4243 | Recall: 0.2627 | Accuracy: 0.9846\n",
      "No improvement in F1 for 3 epoch(s)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 477/477 [10:42<00:00,  1.35s/it, loss=0.5279]\n",
      "Eval: 100%|██████████| 13/13 [00:15<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | Train Loss: 0.4534 | Val Loss: 0.7622 | IoU: 0.2015 | F1: 0.3109 | Precision: 0.4047 | Recall: 0.2882 | Accuracy: 0.9843\n",
      "No improvement in F1 for 4 epoch(s)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 477/477 [10:32<00:00,  1.33s/it, loss=0.7174]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | Train Loss: 0.4527 | Val Loss: 0.7771 | IoU: 0.1956 | F1: 0.3044 | Precision: 0.4485 | Recall: 0.2552 | Accuracy: 0.9848\n",
      "No improvement in F1 for 5 epoch(s)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 477/477 [09:52<00:00,  1.24s/it, loss=0.3691]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 | Train Loss: 0.4521 | Val Loss: 0.7557 | IoU: 0.2066 | F1: 0.3164 | Precision: 0.3990 | Recall: 0.2993 | Accuracy: 0.9843\n",
      "New best model saved (F1: 0.3164)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 477/477 [09:49<00:00,  1.24s/it, loss=0.5754]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 | Train Loss: 0.4514 | Val Loss: 0.7688 | IoU: 0.1997 | F1: 0.3085 | Precision: 0.4189 | Recall: 0.2735 | Accuracy: 0.9845\n",
      "No improvement in F1 for 1 epoch(s)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 477/477 [09:49<00:00,  1.24s/it, loss=0.5774]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 | Train Loss: 0.4508 | Val Loss: 0.7721 | IoU: 0.1948 | F1: 0.3028 | Precision: 0.4135 | Recall: 0.2689 | Accuracy: 0.9845\n",
      "No improvement in F1 for 2 epoch(s)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 477/477 [10:03<00:00,  1.27s/it, loss=0.5086]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 | Train Loss: 0.4503 | Val Loss: 0.7726 | IoU: 0.1965 | F1: 0.3062 | Precision: 0.4378 | Recall: 0.2673 | Accuracy: 0.9846\n",
      "No improvement in F1 for 3 epoch(s)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 477/477 [09:48<00:00,  1.23s/it, loss=0.5295]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 | Train Loss: 0.4498 | Val Loss: 0.7598 | IoU: 0.2037 | F1: 0.3130 | Precision: 0.4037 | Recall: 0.2926 | Accuracy: 0.9844\n",
      "No improvement in F1 for 4 epoch(s)\n",
      "Current lr: 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 477/477 [09:48<00:00,  1.23s/it, loss=0.5494]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 | Train Loss: 0.4492 | Val Loss: 0.7689 | IoU: 0.1986 | F1: 0.3075 | Precision: 0.4205 | Recall: 0.2710 | Accuracy: 0.9846\n",
      "No improvement in F1 for 5 epoch(s)\n",
      "Current lr: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 477/477 [09:48<00:00,  1.23s/it, loss=0.4504]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 | Train Loss: 0.4485 | Val Loss: 0.7698 | IoU: 0.1985 | F1: 0.3059 | Precision: 0.4171 | Recall: 0.2722 | Accuracy: 0.9845\n",
      "No improvement in F1 for 6 epoch(s)\n",
      "Current lr: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 477/477 [09:48<00:00,  1.23s/it, loss=0.4136]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 | Train Loss: 0.4484 | Val Loss: 0.7829 | IoU: 0.1901 | F1: 0.2984 | Precision: 0.4382 | Recall: 0.2478 | Accuracy: 0.9847\n",
      "No improvement in F1 for 7 epoch(s)\n",
      "Current lr: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 477/477 [09:48<00:00,  1.23s/it, loss=0.3470]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 | Train Loss: 0.4484 | Val Loss: 0.7725 | IoU: 0.1956 | F1: 0.3045 | Precision: 0.4267 | Recall: 0.2639 | Accuracy: 0.9846\n",
      "No improvement in F1 for 8 epoch(s)\n",
      "Current lr: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 477/477 [09:48<00:00,  1.23s/it, loss=0.2444]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 | Train Loss: 0.4483 | Val Loss: 0.7805 | IoU: 0.1903 | F1: 0.2973 | Precision: 0.4326 | Recall: 0.2520 | Accuracy: 0.9847\n",
      "No improvement in F1 for 9 epoch(s)\n",
      "Current lr: 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 477/477 [09:48<00:00,  1.23s/it, loss=0.3082]\n",
      "Eval: 100%|██████████| 13/13 [00:12<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 | Train Loss: 0.4482 | Val Loss: 0.7668 | IoU: 0.2011 | F1: 0.3097 | Precision: 0.4185 | Recall: 0.2741 | Accuracy: 0.9844\n",
      "No improvement in F1 for 10 epoch(s)\n",
      "Current lr: 1.0000000000000004e-08\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop with early stopping\n",
    "num_epochs = 50\n",
    "best_f1 = -1.0\n",
    "patience = 10\n",
    "no_improve_epochs = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    tr_loss = train_epoch(model, train_loader, criterion, optimizer, epoch)\n",
    "    val_loss, metrics = evaluate(model, val_loader, criterion)\n",
    "    scheduler.step(val_loss)\n",
    "    lr_now = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch}/{num_epochs} | \"\n",
    "        f\"Train Loss: {tr_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "        f\"IoU: {metrics['jaccard']:.4f} | \"\n",
    "        f\"F1: {metrics['f1_score']:.4f} | \"\n",
    "        f\"Precision: {metrics['precision']:.4f} | \"\n",
    "        f\"Recall: {metrics['recall']:.4f} | \"\n",
    "        f\"Accuracy: {metrics['accuracy']:.4f}\"\n",
    "    )\n",
    "\n",
    "    if metrics[\"f1_score\"] > best_f1:\n",
    "        best_f1 = metrics[\"f1_score\"]\n",
    "        no_improve_epochs = 0  # reset counter\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, \"best_model.pth\"))\n",
    "        print(f\"New best model saved (F1: {best_f1:.4f})\")\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "        print(f\"No improvement in F1 for {no_improve_epochs} epoch(s)\")\n",
    "\n",
    "    print(f\"Current lr: {lr_now}\")\n",
    "\n",
    "    if no_improve_epochs >= patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fae23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating visualizations for best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 14/14 [00:18<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Metrics:\n",
      "  Accuracy: 0.9891\n",
      "  Precision: 0.4709\n",
      "  Recall: 0.2234\n",
      "  F1_score: 0.2789\n",
      "  Jaccard: 0.1720\n",
      "Predictions & visualizations saved to: ./predictions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation with visualisations\n",
    "print(\"Generating visualizations for best model\")\n",
    "model.load_state_dict(torch.load(os.path.join(output_dir, \"best_model.pth\")))\n",
    "_, final_metrics = evaluate(model, test_loader, criterion, save_preds=True)\n",
    "print(\"Final Test Metrics:\")\n",
    "for k, v in final_metrics.items():\n",
    "    print(f\"  {k.capitalize()}: {v:.4f}\")\n",
    "print(f\"Predictions & visualizations saved to: {output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
