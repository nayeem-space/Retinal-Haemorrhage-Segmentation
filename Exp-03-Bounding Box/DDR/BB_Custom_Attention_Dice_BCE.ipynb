{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e6604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seeding(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61035cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"BB_Custom_Attention_MODEL_Dice_BCE\"\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb489b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.smooth = smooth\n",
    "        self.bce_fn = nn.BCEWithLogitsLoss(reduction='none')  # <- changed\n",
    "\n",
    "    def forward(self, logits, targets, reduction='mean'):\n",
    "        # BCE loss map (per-pixel)\n",
    "        bce_loss = self.bce_fn(logits, targets)  # shape: (B, 1, H, W)\n",
    "\n",
    "        # Dice loss (per-batch)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        batch_size = probs.shape[0]\n",
    "        dice_losses = []\n",
    "        for i in range(batch_size):\n",
    "            p = probs[i].view(-1)\n",
    "            g = targets[i].view(-1)\n",
    "            inter = (p * g).sum()\n",
    "            dice = 1 - (2*inter + self.smooth) / (p.sum() + g.sum() + self.smooth)\n",
    "            dice_losses.append(dice)\n",
    "        dice_loss = torch.stack(dice_losses).mean()\n",
    "\n",
    "        if reduction == 'none':\n",
    "            # Used for pixel-wise loss map\n",
    "            return self.alpha + (1 - self.alpha) * bce_loss\n",
    "        else:\n",
    "            return self.alpha * dice_loss + (1 - self.alpha) * bce_loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Definition \n",
    "class HemorrhageDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(images_dir, '*')))\n",
    "        self.mask_paths = sorted(glob.glob(os.path.join(masks_dir, '*')))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        mask = Image.open(self.mask_paths[idx]).convert('L')\n",
    "\n",
    "        # Extract only the green channel as a single-channel image\n",
    "        img_np = np.array(img)[:, :, 1]  # green channel\n",
    "        img = Image.fromarray(img_np)   # convert back to PIL Image (mode 'L')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        mask = (mask > 0).float()\n",
    "\n",
    "        filename = os.path.basename(self.image_paths[idx])\n",
    "        return img, mask, filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1119bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Additive attention block for U-Net skip connections.\"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        # W_g: gating signal transform\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # W_x: skip connection transform\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        # psi: attention coefficient\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        # g: gating signal (from decoder), x: skip features (from encoder)\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi  # apply attention\n",
    "\n",
    "\n",
    "class TripleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 3 times.\"\"\"\n",
    "    def __init__(self, in_c, mid1_c, mid2_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid1_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid1_c)\n",
    "        self.conv2 = nn.Conv2d(mid1_c, mid2_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(mid2_c)\n",
    "        self.conv3 = nn.Conv2d(mid2_c, out_c, 3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 2 times.\"\"\"\n",
    "    def __init__(self, in_c, mid_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid_c)\n",
    "        self.conv2 = nn.Conv2d(mid_c, out_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net with attention gates on skip connections and additional subsampling concat.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.down1 = TripleConv(1, 32, 32, 64)\n",
    "        self.down2 = TripleConv(64, 64, 64, 128)\n",
    "        self.down3 = DoubleConv(128, 128, 256)\n",
    "        self.down4 = DoubleConv(256, 256, 256)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(256, 512, 256)\n",
    "\n",
    "        # Decoder up and conv\n",
    "        self.up4  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec4 = DoubleConv(256+256, 256, 256)\n",
    "        self.up3  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec3 = DoubleConv(256+256, 128, 128)\n",
    "        self.up2  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec2 = TripleConv(128+128, 64, 64, 64)\n",
    "        self.up1  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec1 = TripleConv(64+64, 32, 32, 32)\n",
    "\n",
    "        # Attention blocks for skip connections\n",
    "        self.att4 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att3 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att2 = AttentionBlock(F_g=128, F_l=128, F_int=64)\n",
    "        self.att1 = AttentionBlock(F_g=64,  F_l=64,  F_int=32)\n",
    "\n",
    "        # Final subsample, concat and output\n",
    "        self.final_pool       = nn.MaxPool2d(2, 2)\n",
    "        self.final_upsample   = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.out_conv         = nn.Conv2d(33, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_image = x\n",
    "        # Encoder\n",
    "        x1  = self.down1(x)\n",
    "        x1p = self.pool(x1)\n",
    "        x2  = self.down2(x1p)\n",
    "        x2p = self.pool(x2)\n",
    "        x3  = self.down3(x2p)\n",
    "        x3p = self.pool(x3)\n",
    "        x4  = self.down4(x3p)\n",
    "        x4p = self.pool(x4)\n",
    "\n",
    "        # Bottleneck\n",
    "        xb  = self.bottleneck(x4p)\n",
    "\n",
    "        # Decoder + Attention\n",
    "        d4  = self.up4(xb)\n",
    "        x4a = self.att4(g=d4, x=x4)\n",
    "        d4  = torch.cat([x4a, d4], dim=1)\n",
    "        d4  = self.dec4(d4)\n",
    "\n",
    "        d3  = self.up3(d4)\n",
    "        x3a = self.att3(g=d3, x=x3)\n",
    "        d3  = torch.cat([x3a, d3], dim=1)\n",
    "        d3  = self.dec3(d3)\n",
    "\n",
    "        d2  = self.up2(d3)\n",
    "        x2a = self.att2(g=d2, x=x2)\n",
    "        d2  = torch.cat([x2a, d2], dim=1)\n",
    "        d2  = self.dec2(d2)\n",
    "\n",
    "        d1  = self.up1(d2)\n",
    "        x1a = self.att1(g=d1, x=x1)\n",
    "        d1  = torch.cat([x1a, d1], dim=1)\n",
    "        d1  = self.dec1(d1)\n",
    "\n",
    "        # Additional subsampling & concatenation\n",
    "        d1s = self.final_pool(d1)\n",
    "        ins = self.final_pool(input_image)\n",
    "        cat = torch.cat([d1s, ins], dim=1)\n",
    "        out = self.final_upsample(cat)\n",
    "        out = self.out_conv(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f4e78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Utilities --------\n",
    "def get_bounding_boxes(binary_mask):\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return [cv2.boundingRect(cnt) for cnt in contours]\n",
    "\n",
    "def box_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0]+boxA[2], boxB[0]+boxB[2])\n",
    "    yB = min(boxA[1]+boxA[3], boxB[1]+boxB[3])\n",
    "    interW = max(0, xB - xA)\n",
    "    interH = max(0, yB - yA)\n",
    "    interArea = interW * interH\n",
    "    areaA = boxA[2] * boxA[3]\n",
    "    areaB = boxB[2] * boxB[3]\n",
    "    return interArea / float(areaA + areaB - interArea + 1e-6)\n",
    "\n",
    "def compute_detection_metrics(gt_boxes, pred_boxes, iou_thresh=0.5):\n",
    "    matched_gt = set()\n",
    "    tp = 0\n",
    "    for pb in pred_boxes:\n",
    "        best_iou, best_j = 0, -1\n",
    "        for j, gb in enumerate(gt_boxes):\n",
    "            if j in matched_gt: continue\n",
    "            iou = box_iou(pb, gb)\n",
    "            if iou > best_iou:\n",
    "                best_iou, best_j = iou, j\n",
    "        if best_iou >= iou_thresh:\n",
    "            tp += 1; matched_gt.add(best_j)\n",
    "    fp = len(pred_boxes) - tp\n",
    "    fn = len(gt_boxes) - tp\n",
    "    prec = tp / (tp + fp + 1e-6)\n",
    "    rec  = tp / (tp + fn + 1e-6)\n",
    "    f1   = 2*prec*rec / (prec + rec + 1e-6)\n",
    "    return prec, rec, f1\n",
    "\n",
    "def mask_iou(gt, pred):\n",
    "    gt_bool = gt.astype(bool)\n",
    "    pred_bool = pred.astype(bool)\n",
    "    inter = np.logical_and(gt_bool, pred_bool).sum()\n",
    "    union = np.logical_or(gt_bool, pred_bool).sum()\n",
    "    return inter / (union + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8336a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function \n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, masks, _ in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(imgs)\n",
    "\n",
    "        # Apply pixel-wise loss weighting based on bounding boxes\n",
    "        weights = torch.ones_like(masks)\n",
    "\n",
    "        for i in range(masks.size(0)):\n",
    "            # Convert mask to numpy and extract boxes\n",
    "            mask_np = (masks[i][0].cpu().numpy() * 255).astype(np.uint8)\n",
    "            boxes = get_bounding_boxes(mask_np)\n",
    "            \n",
    "            # Create weight map for that sample\n",
    "            for x, y, w, h in boxes:\n",
    "                weights[i, 0, y:y+h, x:x+w] = 3.0  # Weight 3x inside the box\n",
    "\n",
    "        # Compute loss with weights\n",
    "        loss = criterion(preds, masks)\n",
    "        weighted_loss = (loss * weights).mean()\n",
    "\n",
    "        weighted_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += weighted_loss.item()\n",
    "\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "# Validation Function \n",
    "def validate(model, loader, criterion, iou_thresh, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    metrics = {'prec': [], 'rec': [], 'f1': [], 'iou': []}\n",
    "    with torch.no_grad():\n",
    "        for img, mask, _ in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            img, mask = img.to(device), mask.to(device)\n",
    "            pred = torch.sigmoid(model(img))\n",
    "            loss = criterion(pred, mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pred_bin = (pred > 0.5).float()\n",
    "            gt_np = (mask[0][0].cpu().numpy()*255).astype(np.uint8)\n",
    "            pr_np = (pred_bin[0][0].cpu().numpy()*255).astype(np.uint8)\n",
    "            boxes_gt = get_bounding_boxes(gt_np)\n",
    "            boxes_pr = get_bounding_boxes(pr_np)\n",
    "            p, r, f1 = compute_detection_metrics(boxes_gt, boxes_pr, iou_thresh)\n",
    "            j = mask_iou(gt_np, pr_np)\n",
    "            metrics['prec'].append(p)\n",
    "            metrics['rec'].append(r)\n",
    "            metrics['f1'].append(f1)\n",
    "            metrics['iou'].append(j)\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return avg_loss, {k: np.mean(v) for k, v in metrics.items()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "dataset_dir = '../final_dataset'\n",
    "lr = 1e-4\n",
    "iou_thresh = 0.5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Transforms\n",
    "tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Datasets & Loaders\n",
    "train_img = os.path.join(dataset_dir, 'train', 'images')\n",
    "train_mask = os.path.join(dataset_dir, 'train', 'masks')\n",
    "test_img = os.path.join(dataset_dir, 'test', 'images')\n",
    "test_mask = os.path.join(dataset_dir, 'test', 'masks')\n",
    "\n",
    "\n",
    "\n",
    "train_ds = HemorrhageDataset(train_img, train_mask, transform=tf)\n",
    "full_test = HemorrhageDataset(test_img, test_mask, transform=tf)\n",
    "val_size = len(full_test) // 2\n",
    "val_ds, final_ds = random_split(full_test, [val_size, len(full_test) - val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "final_loader = DataLoader(final_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "model = UNet().to(device)\n",
    "criterion = DiceBCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 40\n",
    "best_iou = -1.0\n",
    "os.makedirs(f\"{MODEL_NAME}\", exist_ok=True)\n",
    "save_path = os.path.join(f\"{MODEL_NAME}\", f\"{MODEL_NAME}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d9adbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 - Train Loss: 0.4641 |  Val Loss: 0.8379 \n",
      "Prec: 0.2375, Rec: 0.0858, F1: 0.1089, IoU: 0.1291\n",
      "Model saved with IoU: 0.1291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40 - Train Loss: 0.3472 |  Val Loss: 0.8378 \n",
      "Prec: 0.2731, Rec: 0.1964, F1: 0.1935, IoU: 0.2111\n",
      "Model saved with IoU: 0.2111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40 - Train Loss: 0.3270 |  Val Loss: 0.8377 \n",
      "Prec: 0.3856, Rec: 0.1563, F1: 0.1937, IoU: 0.1975\n",
      "No improvement. Patience counter: 1/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40 - Train Loss: 0.3175 |  Val Loss: 0.8376 \n",
      "Prec: 0.3612, Rec: 0.1488, F1: 0.1848, IoU: 0.1945\n",
      "No improvement. Patience counter: 2/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40 - Train Loss: 0.3056 |  Val Loss: 0.8376 \n",
      "Prec: 0.3594, Rec: 0.1490, F1: 0.1827, IoU: 0.1994\n",
      "No improvement. Patience counter: 3/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40 - Train Loss: 0.3009 |  Val Loss: 0.8377 \n",
      "Prec: 0.3034, Rec: 0.1267, F1: 0.1563, IoU: 0.1888\n",
      "No improvement. Patience counter: 4/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40 - Train Loss: 0.2926 |  Val Loss: 0.8375 \n",
      "Prec: 0.3497, Rec: 0.1714, F1: 0.2011, IoU: 0.2278\n",
      "Model saved with IoU: 0.2278\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40 - Train Loss: 0.2846 |  Val Loss: 0.8377 \n",
      "Prec: 0.3647, Rec: 0.1497, F1: 0.1829, IoU: 0.2017\n",
      "No improvement. Patience counter: 1/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40 - Train Loss: 0.2786 |  Val Loss: 0.8378 \n",
      "Prec: 0.3481, Rec: 0.1931, F1: 0.2160, IoU: 0.2309\n",
      "Model saved with IoU: 0.2309\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40 - Train Loss: 0.2747 |  Val Loss: 0.8376 \n",
      "Prec: 0.3576, Rec: 0.1743, F1: 0.2008, IoU: 0.2218\n",
      "No improvement. Patience counter: 1/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40 - Train Loss: 0.2685 |  Val Loss: 0.8373 \n",
      "Prec: 0.3352, Rec: 0.1710, F1: 0.2002, IoU: 0.2279\n",
      "No improvement. Patience counter: 2/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40 - Train Loss: 0.2644 |  Val Loss: 0.8373 \n",
      "Prec: 0.3793, Rec: 0.1939, F1: 0.2253, IoU: 0.2434\n",
      "Model saved with IoU: 0.2434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40 - Train Loss: 0.2605 |  Val Loss: 0.8375 \n",
      "Prec: 0.3869, Rec: 0.1384, F1: 0.1816, IoU: 0.2009\n",
      "No improvement. Patience counter: 1/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40 - Train Loss: 0.2566 |  Val Loss: 0.8374 \n",
      "Prec: 0.4069, Rec: 0.1756, F1: 0.2202, IoU: 0.2312\n",
      "No improvement. Patience counter: 2/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40 - Train Loss: 0.2523 |  Val Loss: 0.8373 \n",
      "Prec: 0.3925, Rec: 0.1745, F1: 0.2136, IoU: 0.2321\n",
      "No improvement. Patience counter: 3/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40 - Train Loss: 0.2489 |  Val Loss: 0.8376 \n",
      "Prec: 0.3421, Rec: 0.1817, F1: 0.2027, IoU: 0.2242\n",
      "No improvement. Patience counter: 4/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40 - Train Loss: 0.2462 |  Val Loss: 0.8374 \n",
      "Prec: 0.3546, Rec: 0.1868, F1: 0.2149, IoU: 0.2369\n",
      "No improvement. Patience counter: 5/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40 - Train Loss: 0.2427 |  Val Loss: 0.8372 \n",
      "Prec: 0.3792, Rec: 0.1664, F1: 0.2088, IoU: 0.2519\n",
      "Model saved with IoU: 0.2519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40 - Train Loss: 0.2387 |  Val Loss: 0.8374 \n",
      "Prec: 0.3678, Rec: 0.1570, F1: 0.1959, IoU: 0.2275\n",
      "No improvement. Patience counter: 1/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40 - Train Loss: 0.2380 |  Val Loss: 0.8377 \n",
      "Prec: 0.3689, Rec: 0.1434, F1: 0.1816, IoU: 0.2021\n",
      "No improvement. Patience counter: 2/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40 - Train Loss: 0.2337 |  Val Loss: 0.8373 \n",
      "Prec: 0.3564, Rec: 0.1628, F1: 0.1950, IoU: 0.2403\n",
      "No improvement. Patience counter: 3/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40 - Train Loss: 0.2324 |  Val Loss: 0.8375 \n",
      "Prec: 0.3748, Rec: 0.1551, F1: 0.1963, IoU: 0.2202\n",
      "No improvement. Patience counter: 4/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40 - Train Loss: 0.2291 |  Val Loss: 0.8374 \n",
      "Prec: 0.3717, Rec: 0.1879, F1: 0.2198, IoU: 0.2387\n",
      "No improvement. Patience counter: 5/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40 - Train Loss: 0.2269 |  Val Loss: 0.8373 \n",
      "Prec: 0.4104, Rec: 0.1860, F1: 0.2246, IoU: 0.2479\n",
      "No improvement. Patience counter: 6/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/40 - Train Loss: 0.2253 |  Val Loss: 0.8377 \n",
      "Prec: 0.3600, Rec: 0.1463, F1: 0.1818, IoU: 0.2005\n",
      "No improvement. Patience counter: 7/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40 - Train Loss: 0.2226 |  Val Loss: 0.8373 \n",
      "Prec: 0.3667, Rec: 0.1812, F1: 0.2126, IoU: 0.2462\n",
      "No improvement. Patience counter: 8/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40 - Train Loss: 0.2202 |  Val Loss: 0.8372 \n",
      "Prec: 0.3774, Rec: 0.1887, F1: 0.2268, IoU: 0.2596\n",
      "Model saved with IoU: 0.2596\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40 - Train Loss: 0.2214 |  Val Loss: 0.8374 \n",
      "Prec: 0.3582, Rec: 0.1603, F1: 0.1947, IoU: 0.2155\n",
      "No improvement. Patience counter: 1/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40 - Train Loss: 0.2179 |  Val Loss: 0.8373 \n",
      "Prec: 0.3825, Rec: 0.1714, F1: 0.2107, IoU: 0.2356\n",
      "No improvement. Patience counter: 2/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40 - Train Loss: 0.2157 |  Val Loss: 0.8376 \n",
      "Prec: 0.3716, Rec: 0.1924, F1: 0.2186, IoU: 0.2589\n",
      "No improvement. Patience counter: 3/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40 - Train Loss: 0.2142 |  Val Loss: 0.8373 \n",
      "Prec: 0.3765, Rec: 0.1830, F1: 0.2184, IoU: 0.2506\n",
      "No improvement. Patience counter: 4/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40 - Train Loss: 0.2139 |  Val Loss: 0.8373 \n",
      "Prec: 0.4124, Rec: 0.1975, F1: 0.2364, IoU: 0.2621\n",
      "Model saved with IoU: 0.2621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40 - Train Loss: 0.2107 |  Val Loss: 0.8374 \n",
      "Prec: 0.3645, Rec: 0.1932, F1: 0.2201, IoU: 0.2486\n",
      "No improvement. Patience counter: 1/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/40 - Train Loss: 0.2102 |  Val Loss: 0.8373 \n",
      "Prec: 0.4149, Rec: 0.1856, F1: 0.2293, IoU: 0.2528\n",
      "No improvement. Patience counter: 2/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/40 - Train Loss: 0.2087 |  Val Loss: 0.8374 \n",
      "Prec: 0.3972, Rec: 0.1541, F1: 0.1973, IoU: 0.2254\n",
      "No improvement. Patience counter: 3/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/40 - Train Loss: 0.2066 |  Val Loss: 0.8373 \n",
      "Prec: 0.3575, Rec: 0.2085, F1: 0.2338, IoU: 0.2555\n",
      "No improvement. Patience counter: 4/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/40 - Train Loss: 0.2064 |  Val Loss: 0.8373 \n",
      "Prec: 0.3963, Rec: 0.2068, F1: 0.2360, IoU: 0.2644\n",
      "Model saved with IoU: 0.2644\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/40 - Train Loss: 0.2040 |  Val Loss: 0.8373 \n",
      "Prec: 0.4042, Rec: 0.1799, F1: 0.2179, IoU: 0.2522\n",
      "No improvement. Patience counter: 1/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/40 - Train Loss: 0.2040 |  Val Loss: 0.8372 \n",
      "Prec: 0.4123, Rec: 0.1868, F1: 0.2264, IoU: 0.2548\n",
      "No improvement. Patience counter: 2/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40 - Train Loss: 0.2019 |  Val Loss: 0.8372 \n",
      "Prec: 0.3871, Rec: 0.1752, F1: 0.2124, IoU: 0.2489\n",
      "No improvement. Patience counter: 3/15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_iou = -1.0\n",
    "patience = 15\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_metrics = validate(model, val_loader, criterion, iou_thresh, device)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs} - Train Loss: {train_loss:.4f} | \",\n",
    "          f\"Val Loss: {val_loss:.4f} \\nPrec: {val_metrics['prec']:.4f},\",\n",
    "          f\"Rec: {val_metrics['rec']:.4f}, F1: {val_metrics['f1']:.4f}, IoU: {val_metrics['iou']:.4f}\")\n",
    "\n",
    "    if val_metrics['iou'] > best_iou:\n",
    "        best_iou = val_metrics['iou']\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Model saved with IoU: {best_iou:.4f}\")\n",
    "        patience_counter = 0  # reset if improved\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience counter: {patience_counter}/{patience}\")\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
    "        break\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b5118-ba4f-4ea5-a2bd-af7723d7d14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96387/1914785725.py:100: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_path))\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Summary: {'Precision': 0.3541874737398547, 'Recall': 0.2522272299324383, 'F1': 0.23466042208540522, 'IoU': 0.23988951882244078, 'Box Coverage': 0.1878297493758683}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def test_model(model, loader, iou_thresh, device, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    results = {'prec': [], 'rec': [], 'f1': [], 'ious': []}\n",
    "    total_gt_area = 0\n",
    "    covered_gt_area = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, mask, name in tqdm(loader, desc=\"Testing\", leave=False):\n",
    "            fname = name[0] if isinstance(name, (list, tuple)) else name\n",
    "            img, mask = img.to(device), mask.to(device)\n",
    "            pred = torch.sigmoid(model(img))\n",
    "            pred_bin = (pred > 0.5).float()\n",
    "\n",
    "            # Convert tensors to numpy arrays\n",
    "            img_np = (img[0][0].cpu().numpy() * 255).astype(np.uint8)  # shape: (H, W)\n",
    "            gt_np  = (mask[0][0].cpu().numpy() * 255).astype(np.uint8)\n",
    "            pr_np  = (pred_bin[0][0].cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "            # Bounding boxes and metrics\n",
    "            boxes_gt = get_bounding_boxes(gt_np)\n",
    "            boxes_pr = get_bounding_boxes(pr_np)\n",
    "            p, r, f1 = compute_detection_metrics(boxes_gt, boxes_pr, iou_thresh)\n",
    "            iou = mask_iou(gt_np, pr_np)\n",
    "\n",
    "            # Track metrics\n",
    "            results['prec'].append(p)\n",
    "            results['rec'].append(r)\n",
    "            results['f1'].append(f1)\n",
    "            results['ious'].append(iou)\n",
    "\n",
    "            # Area-based Box Coverage Calculation\n",
    "            for gb in boxes_gt:\n",
    "                x, y, w, h = gb\n",
    "                gt_area = w * h\n",
    "                total_gt_area += gt_area\n",
    "\n",
    "                max_iou = 0\n",
    "                for pb in boxes_pr:\n",
    "                    iou_val = box_iou(pb, gb)\n",
    "                    if iou_val > max_iou:\n",
    "                        max_iou = iou_val\n",
    "\n",
    "                if max_iou >= iou_thresh:\n",
    "                    covered_gt_area += gt_area\n",
    "\n",
    "            # Create composite image (4-panel BGR)\n",
    "            h, w = img_np.shape\n",
    "            spacing = 10\n",
    "            comp_w = w * 4 + spacing * 3\n",
    "            comp_h = h\n",
    "            composite = np.ones((comp_h, comp_w, 3), dtype=np.uint8) * 255\n",
    "\n",
    "            # Convert grayscale to BGR\n",
    "            img_color = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)\n",
    "            gt_overlay = img_color.copy()\n",
    "            pr_overlay = img_color.copy()\n",
    "            both_overlay = img_color.copy()\n",
    "\n",
    "            # Draw boxes\n",
    "            for x, y, ww, hh in boxes_gt:\n",
    "                cv2.rectangle(gt_overlay, (x, y), (x + ww, y + hh), (0, 255, 0), 2)\n",
    "                cv2.rectangle(both_overlay, (x, y), (x + ww, y + hh), (0, 255, 0), 2)\n",
    "            for x, y, ww, hh in boxes_pr:\n",
    "                cv2.rectangle(pr_overlay, (x, y), (x + ww, y + hh), (255, 0, 0), 2)\n",
    "                cv2.rectangle(both_overlay, (x, y), (x + ww, y + hh), (255, 0, 0), 2)\n",
    "\n",
    "            # Assemble composite\n",
    "            composite[0:h, 0:w] = img_color\n",
    "            composite[0:h, w + spacing:w * 2 + spacing] = gt_overlay\n",
    "            composite[0:h, w * 2 + spacing * 2:w * 3 + spacing * 2] = pr_overlay\n",
    "            composite[0:h, w * 3 + spacing * 3:w * 4 + spacing * 3] = both_overlay\n",
    "\n",
    "            # Save composite image\n",
    "            Image.fromarray(composite).save(os.path.join(out_dir, fname))\n",
    "\n",
    "    # Compute area-based Box Coverage\n",
    "    box_coverage = covered_gt_area / (total_gt_area + 1e-6)\n",
    "\n",
    "    # Summary metrics\n",
    "    summary = {\n",
    "        'Precision': np.mean(results['prec']),\n",
    "        'Recall': np.mean(results['rec']),\n",
    "        'F1': np.mean(results['f1']),\n",
    "        'IoU': np.mean(results['ious']) if results['ious'] else 0.0,\n",
    "        'Box Coverage': box_coverage\n",
    "    }\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Test\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "summary = test_model(model, final_loader, iou_thresh, device, out_dir=os.path.join('.', f\"{MODEL_NAME}_Result\"))\n",
    "print(\"Test Summary:\", summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
