{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e6604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "def seeding(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seeding(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61035cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"BB_Custom_MODEL_Dice_BCE\"\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb489b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, alpha=0.5, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.smooth = smooth\n",
    "        self.bce_fn = nn.BCEWithLogitsLoss(reduction='none')  #  changed\n",
    "\n",
    "    def forward(self, logits, targets, reduction='mean'):\n",
    "        # BCE loss map (per-pixel)\n",
    "        bce_loss = self.bce_fn(logits, targets)  # shape: (B, 1, H, W)\n",
    "\n",
    "        # Dice loss (per-batch)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        batch_size = probs.shape[0]\n",
    "        dice_losses = []\n",
    "        for i in range(batch_size):\n",
    "            p = probs[i].view(-1)\n",
    "            g = targets[i].view(-1)\n",
    "            inter = (p * g).sum()\n",
    "            dice = 1 - (2*inter + self.smooth) / (p.sum() + g.sum() + self.smooth)\n",
    "            dice_losses.append(dice)\n",
    "        dice_loss = torch.stack(dice_losses).mean()\n",
    "\n",
    "        if reduction == 'none':\n",
    "            # Used for pixel-wise loss map\n",
    "            return self.alpha + (1 - self.alpha) * bce_loss\n",
    "        else:\n",
    "            return self.alpha * dice_loss + (1 - self.alpha) * bce_loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ef4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Dataset Definition --------\n",
    "class HemorrhageDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(images_dir, '*')))\n",
    "        self.mask_paths = sorted(glob.glob(os.path.join(masks_dir, '*')))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        mask = Image.open(self.mask_paths[idx]).convert('L')\n",
    "\n",
    "        # Extract only the green channel as a single-channel image\n",
    "        img_np = np.array(img)[:, :, 1]  # green channel\n",
    "        img = Image.fromarray(img_np)   # convert back to PIL Image (mode 'L')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        mask = (mask > 0).float()\n",
    "\n",
    "        filename = os.path.basename(self.image_paths[idx])\n",
    "        return img, mask, filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119bce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  DoubleConv and TripleConv\n",
    "\n",
    "class TripleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 3 times.\"\"\"\n",
    "    def __init__(self, in_c, mid1_c, mid2_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid1_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid1_c)\n",
    "        self.conv2 = nn.Conv2d(mid1_c, mid2_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(mid2_c)\n",
    "        self.conv3 = nn.Conv2d(mid2_c, out_c, 3, padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        return x\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Conv -> BN -> ReLU repeated 2 times.\"\"\"\n",
    "    def __init__(self, in_c, mid_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, mid_c, 3, padding=1)\n",
    "        self.bn1   = nn.BatchNorm2d(mid_c)\n",
    "        self.conv2 = nn.Conv2d(mid_c, out_c, 3, padding=1)\n",
    "        self.bn2   = nn.BatchNorm2d(out_c)\n",
    "        self.relu  = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "#  UNetRetina (with additional subsampling and concatenation)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ENCODER \n",
    "        # Block 1: 3 conv -> (32, 32, 64)\n",
    "        self.down1 = TripleConv(\n",
    "            in_c=1,       # green channel only\n",
    "            mid1_c=32,\n",
    "            mid2_c=32,\n",
    "            out_c=64\n",
    "        )\n",
    "        # Block 2: 3 conv -> (64, 64, 128)\n",
    "        self.down2 = TripleConv(\n",
    "            in_c=64,\n",
    "            mid1_c=64,\n",
    "            mid2_c=64,\n",
    "            out_c=128\n",
    "        )\n",
    "        # Block 3: 2 conv -> (128, 128, 256)\n",
    "        self.down3 = DoubleConv(\n",
    "            in_c=128,\n",
    "            mid_c=128,\n",
    "            out_c=256\n",
    "        )\n",
    "        # Block 4: 2 conv -> (256, 256, 256)\n",
    "        self.down4 = DoubleConv(\n",
    "            in_c=256,\n",
    "            mid_c=256,\n",
    "            out_c=256\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "    \n",
    "        # Bottleneck: 2 conv -> (256 -> 512 -> 256)\n",
    "\n",
    "        self.bottleneck = DoubleConv(\n",
    "            in_c=256,\n",
    "            mid_c=512,\n",
    "            out_c=256\n",
    "        )\n",
    "        \n",
    "        # DECODER \n",
    "        # Each decoder block: upsample, concat skip connection, then decode.\n",
    "        self.up4  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec4 = DoubleConv(in_c=256+256, mid_c=256, out_c=256)\n",
    "        \n",
    "        self.up3  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec3 = DoubleConv(in_c=256+256, mid_c=128, out_c=128)\n",
    "        \n",
    "        self.up2  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec2 = TripleConv(in_c=128+128, mid1_c=64, mid2_c=64, out_c=64)\n",
    "        \n",
    "        self.up1  = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.dec1 = TripleConv(in_c=64+64, mid1_c=32, mid2_c=32, out_c=32)\n",
    "        \n",
    "        #  ADDITIONAL SUBSAMPLING & CONCATENATION \n",
    "        self.final_pool = nn.MaxPool2d(2, 2)  # Additional subsampling step\n",
    "        self.final_upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        # After concatenation: 32 channels (from decoder) + 1 channel (from input) = 33 channels\n",
    "        self.out_conv = nn.Conv2d(33, 1, kernel_size=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # -------- Encoder --------\n",
    "        input_image = x\n",
    "        \n",
    "        # Block 1\n",
    "        x1 = self.down1(x)    #  64 channels\n",
    "        x1p = self.pool(x1)   # subsampled\n",
    "        \n",
    "        # Block 2\n",
    "        x2 = self.down2(x1p)  # 128 channels\n",
    "        x2p = self.pool(x2)   # subsampled\n",
    "        \n",
    "        # Block 3\n",
    "        x3 = self.down3(x2p)  # 256 channels\n",
    "        x3p = self.pool(x3)   # subsampled\n",
    "        \n",
    "        # Block 4\n",
    "        x4 = self.down4(x3p)  # 256 channels\n",
    "        x4p = self.pool(x4)   # subsampled\n",
    "        \n",
    "        #  Bottleneck \n",
    "        xb = self.bottleneck(x4p)  # 256 -> 512 -> 256\n",
    "        \n",
    "        #  Decoder \n",
    "        xd4 = self.up4(xb)               \n",
    "        xd4 = torch.cat([x4, xd4], dim=1)  \n",
    "        xd4 = self.dec4(xd4)             \n",
    "        \n",
    "        xd3 = self.up3(xd4)              \n",
    "        xd3 = torch.cat([x3, xd3], dim=1) \n",
    "        xd3 = self.dec3(xd3)             \n",
    "        \n",
    "        xd2 = self.up2(xd3)              \n",
    "        xd2 = torch.cat([x2, xd2], dim=1) \n",
    "        xd2 = self.dec2(xd2)             \n",
    "        \n",
    "        xd1 = self.up1(xd2)              \n",
    "        xd1 = torch.cat([x1, xd1], dim=1) \n",
    "        xd1 = self.dec1(xd1)             \n",
    "        \n",
    "        # Additional Subsampling & Concatenation \n",
    "        xd1_sub = self.final_pool(xd1)          # [B,32,H/2,W/2]\n",
    "        input_sub = self.final_pool(input_image) # [B,1,H/2,W/2]\n",
    "        final_cat = torch.cat([xd1_sub, input_sub], dim=1)  # [B,33,H/2,W/2]\n",
    "        final_up = self.final_upsample(final_cat)  # [B,33,H,W]\n",
    "        \n",
    "        out = self.out_conv(final_up)  # [B,1,H,W]\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4e78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities \n",
    "def get_bounding_boxes(binary_mask):\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return [cv2.boundingRect(cnt) for cnt in contours]\n",
    "\n",
    "def box_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0]+boxA[2], boxB[0]+boxB[2])\n",
    "    yB = min(boxA[1]+boxA[3], boxB[1]+boxB[3])\n",
    "    interW = max(0, xB - xA)\n",
    "    interH = max(0, yB - yA)\n",
    "    interArea = interW * interH\n",
    "    areaA = boxA[2] * boxA[3]\n",
    "    areaB = boxB[2] * boxB[3]\n",
    "    return interArea / float(areaA + areaB - interArea + 1e-6)\n",
    "\n",
    "def compute_detection_metrics(gt_boxes, pred_boxes, iou_thresh=0.5):\n",
    "    matched_gt = set()\n",
    "    tp = 0\n",
    "    for pb in pred_boxes:\n",
    "        best_iou, best_j = 0, -1\n",
    "        for j, gb in enumerate(gt_boxes):\n",
    "            if j in matched_gt: continue\n",
    "            iou = box_iou(pb, gb)\n",
    "            if iou > best_iou:\n",
    "                best_iou, best_j = iou, j\n",
    "        if best_iou >= iou_thresh:\n",
    "            tp += 1; matched_gt.add(best_j)\n",
    "    fp = len(pred_boxes) - tp\n",
    "    fn = len(gt_boxes) - tp\n",
    "    prec = tp / (tp + fp + 1e-6)\n",
    "    rec  = tp / (tp + fn + 1e-6)\n",
    "    f1   = 2*prec*rec / (prec + rec + 1e-6)\n",
    "    return prec, rec, f1\n",
    "\n",
    "def mask_iou(gt, pred):\n",
    "    gt_bool = gt.astype(bool)\n",
    "    pred_bool = pred.astype(bool)\n",
    "    inter = np.logical_and(gt_bool, pred_bool).sum()\n",
    "    union = np.logical_or(gt_bool, pred_bool).sum()\n",
    "    return inter / (union + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8336a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function \n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, masks, _ in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(imgs)\n",
    "\n",
    "        # Apply pixel-wise loss weighting based on bounding boxes\n",
    "        weights = torch.ones_like(masks)\n",
    "\n",
    "        for i in range(masks.size(0)):\n",
    "            # Convert mask to numpy and extract boxes\n",
    "            mask_np = (masks[i][0].cpu().numpy() * 255).astype(np.uint8)\n",
    "            boxes = get_bounding_boxes(mask_np)\n",
    "            \n",
    "            # Create weight map for that sample\n",
    "            for x, y, w, h in boxes:\n",
    "                weights[i, 0, y:y+h, x:x+w] = 3.0  # Weight 3x inside the box\n",
    "\n",
    "        # Compute loss with weights\n",
    "        loss = criterion(preds, masks)\n",
    "        weighted_loss = (loss * weights).mean()\n",
    "\n",
    "        weighted_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += weighted_loss.item()\n",
    "\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "# Validation Function \n",
    "def validate(model, loader, criterion, iou_thresh, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    metrics = {'prec': [], 'rec': [], 'f1': [], 'iou': []}\n",
    "    with torch.no_grad():\n",
    "        for img, mask, _ in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            img, mask = img.to(device), mask.to(device)\n",
    "            pred = torch.sigmoid(model(img))\n",
    "            loss = criterion(pred, mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            pred_bin = (pred > 0.5).float()\n",
    "            gt_np = (mask[0][0].cpu().numpy()*255).astype(np.uint8)\n",
    "            pr_np = (pred_bin[0][0].cpu().numpy()*255).astype(np.uint8)\n",
    "            boxes_gt = get_bounding_boxes(gt_np)\n",
    "            boxes_pr = get_bounding_boxes(pr_np)\n",
    "            p, r, f1 = compute_detection_metrics(boxes_gt, boxes_pr, iou_thresh)\n",
    "            j = mask_iou(gt_np, pr_np)\n",
    "            metrics['prec'].append(p)\n",
    "            metrics['rec'].append(r)\n",
    "            metrics['f1'].append(f1)\n",
    "            metrics['iou'].append(j)\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return avg_loss, {k: np.mean(v) for k, v in metrics.items()}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Setup & Execution (Notebook) \n",
    "# Constants\n",
    "dataset_dir = './final_dataset'\n",
    "lr = 1e-4\n",
    "iou_thresh = 0.5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Transforms\n",
    "tf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Datasets & Loaders\n",
    "train_img = os.path.join(dataset_dir, 'train', 'images')\n",
    "train_mask = os.path.join(dataset_dir, 'train', 'masks')\n",
    "test_img = os.path.join(dataset_dir, 'test', 'images')\n",
    "test_mask = os.path.join(dataset_dir, 'test', 'masks')\n",
    "\n",
    "\n",
    "\n",
    "train_ds = HemorrhageDataset(train_img, train_mask, transform=tf)\n",
    "full_test = HemorrhageDataset(test_img, test_mask, transform=tf)\n",
    "val_size = len(full_test) // 2\n",
    "val_ds, final_ds = random_split(full_test, [val_size, len(full_test) - val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "final_loader = DataLoader(final_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "model = UNet().to(device)\n",
    "criterion = DiceBCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 40\n",
    "best_iou = -1.0\n",
    "os.makedirs(f\"{MODEL_NAME}\", exist_ok=True)\n",
    "save_path = os.path.join(f\"{MODEL_NAME}\", f\"{MODEL_NAME}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d9adbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 - Train Loss: 0.5832 |  Val Loss: 0.8461 \n",
      "Prec: 0.0817, Rec: 0.3168, F1: 0.1171, IoU: 0.1994\n",
      "Model saved with IoU: 0.1994\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40 - Train Loss: 0.4689 |  Val Loss: 0.8361 \n",
      "Prec: 0.0984, Rec: 0.3807, F1: 0.1428, IoU: 0.1940\n",
      "No improvement. Patience counter: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40 - Train Loss: 0.3815 |  Val Loss: 0.8306 \n",
      "Prec: 0.1625, Rec: 0.2904, F1: 0.1994, IoU: 0.2881\n",
      "Model saved with IoU: 0.2881\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40 - Train Loss: 0.3311 |  Val Loss: 0.8298 \n",
      "Prec: 0.2327, Rec: 0.2897, F1: 0.2511, IoU: 0.3077\n",
      "Model saved with IoU: 0.3077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40 - Train Loss: 0.2926 |  Val Loss: 0.8299 \n",
      "Prec: 0.1961, Rec: 0.2983, F1: 0.2255, IoU: 0.3078\n",
      "Model saved with IoU: 0.3078\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40 - Train Loss: 0.2711 |  Val Loss: 0.8298 \n",
      "Prec: 0.2464, Rec: 0.3466, F1: 0.2777, IoU: 0.3069\n",
      "No improvement. Patience counter: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40 - Train Loss: 0.2438 |  Val Loss: 0.8298 \n",
      "Prec: 0.2486, Rec: 0.3078, F1: 0.2649, IoU: 0.3021\n",
      "No improvement. Patience counter: 2/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40 - Train Loss: 0.2290 |  Val Loss: 0.8297 \n",
      "Prec: 0.2519, Rec: 0.2805, F1: 0.2609, IoU: 0.2970\n",
      "No improvement. Patience counter: 3/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40 - Train Loss: 0.2056 |  Val Loss: 0.8302 \n",
      "Prec: 0.2694, Rec: 0.2278, F1: 0.2401, IoU: 0.2664\n",
      "No improvement. Patience counter: 4/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40 - Train Loss: 0.2127 |  Val Loss: 0.8301 \n",
      "Prec: 0.2460, Rec: 0.2672, F1: 0.2521, IoU: 0.2830\n",
      "No improvement. Patience counter: 5/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40 - Train Loss: 0.1808 |  Val Loss: 0.8295 \n",
      "Prec: 0.1828, Rec: 0.3603, F1: 0.2323, IoU: 0.3234\n",
      "Model saved with IoU: 0.3234\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40 - Train Loss: 0.1715 |  Val Loss: 0.8296 \n",
      "Prec: 0.2468, Rec: 0.2848, F1: 0.2530, IoU: 0.3005\n",
      "No improvement. Patience counter: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40 - Train Loss: 0.1800 |  Val Loss: 0.8298 \n",
      "Prec: 0.2484, Rec: 0.3346, F1: 0.2790, IoU: 0.3112\n",
      "No improvement. Patience counter: 2/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40 - Train Loss: 0.1593 |  Val Loss: 0.8294 \n",
      "Prec: 0.2030, Rec: 0.3112, F1: 0.2360, IoU: 0.3140\n",
      "No improvement. Patience counter: 3/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40 - Train Loss: 0.1566 |  Val Loss: 0.8301 \n",
      "Prec: 0.1963, Rec: 0.2381, F1: 0.1974, IoU: 0.2435\n",
      "No improvement. Patience counter: 4/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40 - Train Loss: 0.1447 |  Val Loss: 0.8298 \n",
      "Prec: 0.2611, Rec: 0.2680, F1: 0.2600, IoU: 0.2708\n",
      "No improvement. Patience counter: 5/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40 - Train Loss: 0.1677 |  Val Loss: 0.8303 \n",
      "Prec: 0.2531, Rec: 0.2645, F1: 0.2389, IoU: 0.2616\n",
      "No improvement. Patience counter: 6/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40 - Train Loss: 0.1516 |  Val Loss: 0.8297 \n",
      "Prec: 0.2274, Rec: 0.2565, F1: 0.2276, IoU: 0.2952\n",
      "No improvement. Patience counter: 7/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40 - Train Loss: 0.1381 |  Val Loss: 0.8298 \n",
      "Prec: 0.2722, Rec: 0.2877, F1: 0.2737, IoU: 0.2829\n",
      "No improvement. Patience counter: 8/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40 - Train Loss: 0.1277 |  Val Loss: 0.8296 \n",
      "Prec: 0.3468, Rec: 0.3636, F1: 0.3246, IoU: 0.3236\n",
      "Model saved with IoU: 0.3236\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40 - Train Loss: 0.1278 |  Val Loss: 0.8299 \n",
      "Prec: 0.2686, Rec: 0.3222, F1: 0.2876, IoU: 0.3011\n",
      "No improvement. Patience counter: 1/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40 - Train Loss: 0.1410 |  Val Loss: 0.8303 \n",
      "Prec: 0.2047, Rec: 0.2869, F1: 0.2218, IoU: 0.2737\n",
      "No improvement. Patience counter: 2/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40 - Train Loss: 0.1262 |  Val Loss: 0.8295 \n",
      "Prec: 0.2408, Rec: 0.3518, F1: 0.2791, IoU: 0.3110\n",
      "No improvement. Patience counter: 3/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40 - Train Loss: 0.1141 |  Val Loss: 0.8297 \n",
      "Prec: 0.2160, Rec: 0.3042, F1: 0.2462, IoU: 0.2964\n",
      "No improvement. Patience counter: 4/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/40 - Train Loss: 0.1124 |  Val Loss: 0.8296 \n",
      "Prec: 0.2189, Rec: 0.3050, F1: 0.2492, IoU: 0.3031\n",
      "No improvement. Patience counter: 5/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40 - Train Loss: 0.1332 |  Val Loss: 0.8295 \n",
      "Prec: 0.3070, Rec: 0.2778, F1: 0.2852, IoU: 0.3058\n",
      "No improvement. Patience counter: 6/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40 - Train Loss: 0.1084 |  Val Loss: 0.8296 \n",
      "Prec: 0.1808, Rec: 0.2858, F1: 0.2079, IoU: 0.2953\n",
      "No improvement. Patience counter: 7/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40 - Train Loss: 0.1069 |  Val Loss: 0.8293 \n",
      "Prec: 0.2116, Rec: 0.3257, F1: 0.2523, IoU: 0.3208\n",
      "No improvement. Patience counter: 8/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40 - Train Loss: 0.1048 |  Val Loss: 0.8300 \n",
      "Prec: 0.2263, Rec: 0.3137, F1: 0.2574, IoU: 0.2839\n",
      "No improvement. Patience counter: 9/10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40 - Train Loss: 0.1097 |  Val Loss: 0.8335 \n",
      "Prec: 0.0978, Rec: 0.3785, F1: 0.1403, IoU: 0.1663\n",
      "No improvement. Patience counter: 10/10\n",
      "Early stopping triggered after 10 epochs without improvement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "best_iou = -1.0\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_metrics = validate(model, val_loader, criterion, iou_thresh, device)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs} - Train Loss: {train_loss:.4f} | \",\n",
    "          f\"Val Loss: {val_loss:.4f} \\nPrec: {val_metrics['prec']:.4f},\",\n",
    "          f\"Rec: {val_metrics['rec']:.4f}, F1: {val_metrics['f1']:.4f}, IoU: {val_metrics['iou']:.4f}\")\n",
    "\n",
    "    if val_metrics['iou'] > best_iou:\n",
    "        best_iou = val_metrics['iou']\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Model saved with IoU: {best_iou:.4f}\")\n",
    "        patience_counter = 0  # reset if improved\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience counter: {patience_counter}/{patience}\")\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
    "        break\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00232d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Summary: {'Precision': 0.28094175126760934, 'Recall': 0.34385879927422897, 'F1': 0.3012129937553158, 'IoU': 0.4164911056037921, 'Box Coverage': 0.5668325797849816}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "def test_model(model, loader, iou_thresh, device, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    results = {'prec': [], 'rec': [], 'f1': [], 'ious': []}\n",
    "    total_gt_area = 0\n",
    "    covered_gt_area = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, mask, name in tqdm(loader, desc=\"Testing\", leave=False):\n",
    "            fname = name[0] if isinstance(name, (list, tuple)) else name\n",
    "            img, mask = img.to(device), mask.to(device)\n",
    "            pred = torch.sigmoid(model(img))\n",
    "            pred_bin = (pred > 0.5).float()\n",
    "\n",
    "            # Convert tensors to numpy arrays\n",
    "            img_np = (img[0][0].cpu().numpy() * 255).astype(np.uint8)  # shape: (H, W)\n",
    "            gt_np  = (mask[0][0].cpu().numpy() * 255).astype(np.uint8)\n",
    "            pr_np  = (pred_bin[0][0].cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "            # Bounding boxes and metrics\n",
    "            boxes_gt = get_bounding_boxes(gt_np)\n",
    "            boxes_pr = get_bounding_boxes(pr_np)\n",
    "            p, r, f1 = compute_detection_metrics(boxes_gt, boxes_pr, iou_thresh)\n",
    "            iou = mask_iou(gt_np, pr_np)\n",
    "\n",
    "            # Track metrics\n",
    "            results['prec'].append(p)\n",
    "            results['rec'].append(r)\n",
    "            results['f1'].append(f1)\n",
    "            results['ious'].append(iou)\n",
    "\n",
    "            # Area-based Box Coverage Calculation\n",
    "            for gb in boxes_gt:\n",
    "                x, y, w, h = gb\n",
    "                gt_area = w * h\n",
    "                total_gt_area += gt_area\n",
    "\n",
    "                max_iou = 0\n",
    "                for pb in boxes_pr:\n",
    "                    iou_val = box_iou(pb, gb)\n",
    "                    if iou_val > max_iou:\n",
    "                        max_iou = iou_val\n",
    "\n",
    "                if max_iou >= iou_thresh:\n",
    "                    covered_gt_area += gt_area\n",
    "\n",
    "            # Create composite image (4-panel BGR)\n",
    "            h, w = img_np.shape\n",
    "            spacing = 10\n",
    "            comp_w = w * 4 + spacing * 3\n",
    "            comp_h = h\n",
    "            composite = np.ones((comp_h, comp_w, 3), dtype=np.uint8) * 255\n",
    "\n",
    "            # Convert grayscale to BGR\n",
    "            img_color = cv2.cvtColor(img_np, cv2.COLOR_GRAY2BGR)\n",
    "            gt_overlay = img_color.copy()\n",
    "            pr_overlay = img_color.copy()\n",
    "            both_overlay = img_color.copy()\n",
    "\n",
    "            # Draw boxes\n",
    "            for x, y, ww, hh in boxes_gt:\n",
    "                cv2.rectangle(gt_overlay, (x, y), (x + ww, y + hh), (0, 255, 0), 2)\n",
    "                cv2.rectangle(both_overlay, (x, y), (x + ww, y + hh), (0, 255, 0), 2)\n",
    "            for x, y, ww, hh in boxes_pr:\n",
    "                cv2.rectangle(pr_overlay, (x, y), (x + ww, y + hh), (255, 0, 0), 2)\n",
    "                cv2.rectangle(both_overlay, (x, y), (x + ww, y + hh), (255, 0, 0), 2)\n",
    "\n",
    "            # Assemble composite\n",
    "            composite[0:h, 0:w] = img_color\n",
    "            composite[0:h, w + spacing:w * 2 + spacing] = gt_overlay\n",
    "            composite[0:h, w * 2 + spacing * 2:w * 3 + spacing * 2] = pr_overlay\n",
    "            composite[0:h, w * 3 + spacing * 3:w * 4 + spacing * 3] = both_overlay\n",
    "\n",
    "            # Save composite image\n",
    "            Image.fromarray(composite).save(os.path.join(out_dir, fname))\n",
    "\n",
    "    # Compute area-based Box Coverage\n",
    "    box_coverage = covered_gt_area / (total_gt_area + 1e-6)\n",
    "\n",
    "    # Summary metrics\n",
    "    summary = {\n",
    "        'Precision': np.mean(results['prec']),\n",
    "        'Recall': np.mean(results['rec']),\n",
    "        'F1': np.mean(results['f1']),\n",
    "        'IoU': np.mean(results['ious']) if results['ious'] else 0.0,\n",
    "        'Box Coverage': box_coverage\n",
    "    }\n",
    "\n",
    "    return summary\n",
    "\n",
    "# Test\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "summary = test_model(model, final_loader, iou_thresh, device, out_dir=os.path.join('.', f\"{MODEL_NAME}_Result\"))\n",
    "print(\"Test Summary:\", summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
